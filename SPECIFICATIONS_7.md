# üîß Sp√©cifications Techniques - Ensemble 7

## üéØ T√¢che #27 : Self-Correction Loop

### Objectif
Impl√©menter une boucle d'auto-correction o√π, apr√®s la g√©n√©ration d'une r√©ponse, un "critique" interne l'√©value et, si n√©cessaire, demande une r√©√©criture avant que la r√©ponse finale ne soit envoy√©e √† l'utilisateur.

### Philosophie "Usine Vide"
Nous allons modifier notre TaskExecutor pour orchestrer ce processus. Nous utiliserons notre MockEngine pour simuler √† la fois la g√©n√©ration initiale et la r√©√©criture. Le "critique" sera une simple fonction pour le moment, mais l'architecture sera en place pour le remplacer par un vrai mod√®le plus tard.

### Sp√©cifications Techniques D√©taill√©es

#### 1. Cr√©ation du "Critique" Structur√© avec Scoring D√©taill√©
Ce service simulera l'√©valuation d'une r√©ponse avec un scoring multi-dimensionnel.

```typescript
// src/core/kernel/critics/ResponseCritic.ts (Mise √† jour)

console.log("üßê ResponseCritic (Production) initialis√©.");

export interface Critique {
  is_acceptable: boolean;
  reason?: string;
  correction_suggestions?: string;
  scores?: {
    accuracy: number;
    clarity: number;
    completeness: number;
    safety: number;
  };
}

class ResponseCritic {
  /**
   * Simule l'√©valuation d'une r√©ponse avec scoring d√©taill√©.
   * Attribue un score structur√© (pr√©cision, clart√©, compl√©tude, s√©curit√©) sur 0-1.
   * Une r√©ponse est inacceptable si le score global est < 0.7.
   */
  public async review(prompt: string, response: string): Promise<Critique> {
    console.log("[Critic] √âvaluation de la r√©ponse...");
    await new Promise(r => setTimeout(r, 50)); // Simule le temps d'analyse

    // Calcule les scores d√©taill√©s
    const scores = {
      accuracy: await this.scoreAccuracy(prompt, response),
      clarity: await this.scoreClarity(response),
      completeness: await this.scoreCompleteness(prompt, response),
      safety: await this.scoreSafety(response)
    };

    // Calcule un score global (0-1)
    const globalScore = Object.values(scores).reduce((a, b) => a + b) / 4;

    // Critique bas√©e sur un score structur√©
    if (globalScore < 0.7) {
      const lowestCriterion = Object.entries(scores)
        .sort((a, b) => a[1] - b[1])[0];
      
      console.log(`[Critic] ‚ö†Ô∏è R√©ponse jug√©e inacceptable (score: ${(globalScore * 100).toFixed(0)}%).`);
      return {
        is_acceptable: false,
        reason: `Score insuffisant (${(globalScore * 100).toFixed(0)}%)`,
        correction_suggestions: this.getSuggestion(lowestCriterion[0]),
        scores
      };
    }

    console.log(`[Critic] ‚úÖ R√©ponse jug√©e acceptable (score: ${(globalScore * 100).toFixed(0)}%).`);
    return { is_acceptable: true, scores };
  }

  private async scoreAccuracy(prompt: string, response: string): Promise<number> {
    // V√©rifie si la r√©ponse r√©pond vraiment au prompt
    const keywords = this.extractKeywords(prompt);
    const mentionedKeywords = keywords.filter(k => 
      response.toLowerCase().includes(k.toLowerCase())
    );
    return keywords.length > 0 ? mentionedKeywords.length / keywords.length : 1;
  }

  private async scoreClarity(response: string): Promise<number> {
    // Analyse la lisibilit√©
    const avgSentenceLength = this.getAvgSentenceLength(response);
    const complexWords = this.countComplexWords(response);
    
    // P√©nalise les phrases trop longues (>25 mots) ou trop courtes (<5 mots)
    const clarityPenalty = avgSentenceLength > 25 || avgSentenceLength < 5 ? 0.5 : 1;
    return clarityPenalty * (1 - complexWords / Math.max(1, response.split(' ').length));
  }

  private async scoreCompleteness(prompt: string, response: string): Promise<number> {
    // V√©rifie si tous les aspects du prompt sont couverts
    const questions = this.extractQuestions(prompt);
    const answeredQuestions = questions.filter(q => 
      this.isQuestionAnswered(q, response)
    );
    return questions.length > 0 ? answeredQuestions.length / questions.length : 1;
  }

  private async scoreSafety(response: string): Promise<number> {
    // D√©tecte les contenus probl√©matiques
    const redFlags = ['hack', 'exploit', 'illegal', 'dangerous'];
    const flagsFound = redFlags.filter(flag => 
      response.toLowerCase().includes(flag)
    );
    return 1 - (flagsFound.length * 0.3); // P√©nalit√© de 30% par flag
  }

  private extractKeywords(prompt: string): string[] {
    // Extraction simplifi√©e de mots-cl√©s
    return prompt.toLowerCase().match(/\b(\w{4,})\b/g) || [];
  }

  private getAvgSentenceLength(response: string): number {
    const sentences = response.split(/[.!?]+/).filter(s => s.trim().length > 0);
    const totalWords = sentences.reduce((acc, s) => acc + s.trim().split(/\s+/).length, 0);
    return sentences.length > 0 ? totalWords / sentences.length : 0;
  }

  private countComplexWords(response: string): number {
    // Compte les mots avec plus de 3 syllabes comme mots complexes
    const words = response.toLowerCase().match(/\b\w+\b/g) || [];
    return words.filter(word => this.countSyllables(word) > 3).length;
  }

  private countSyllables(word: string): number {
    // Comptage simplifi√© de syllabes
    word = word.toLowerCase();
    if (word.length <= 3) return 1;
    word = word.replace(/(?:[^laeiouy]es|ed|[^laeiouy]e)$/, '');
    word = word.replace(/^y/, '');
    const matches = word.match(/[aeiouy]{1,2}/g);
    return matches ? matches.length : 1;
  }

  private extractQuestions(prompt: string): string[] {
    // Extraction simplifi√©e de questions
    const questionRegex = /[?]/g;
    const matches = prompt.match(questionRegex);
    return matches ? Array(matches.length).fill("question") : [];
  }

  private isQuestionAnswered(question: string, response: string): boolean {
    // V√©rification simplifi√©e si une question est r√©pondue
    return response.length > 50; // Heuristique basique
  }

  private getSuggestion(criterion: string): string {
    const suggestions: Record<string, string> = {
      accuracy: "Assure-toi de r√©pondre pr√©cis√©ment √† la question pos√©e",
      clarity: "Utilise des phrases plus courtes et plus simples",
      completeness: "Couvre tous les aspects de la question",
      safety: "√âvite les termes probl√©matiques"
    };
    return suggestions[criterion] || "Am√©liore la qualit√© globale de la r√©ponse";
  }
}

export const responseCritic = new ResponseCritic();
```

#### 2. Cr√©ation du Moteur TRM comme Moteur Central d'Auto-Correction
Impl√©mentation d'un moteur TRM qui combine g√©n√©ration ET critique dans un cycle it√©ratif ultra-rapide.

```typescript
// src/core/kernel/engine/TRMEngine.ts (Mise √† jour)

export class TRMEngine {
  /**
   * Int√®gre TRM comme moteur central d'auto-correction.
   * Combine g√©n√©ration ET critique dans un cycle it√©ratif ultra-rapide.
   * Utilise generateWithSelfCorrection qui affine la r√©ponse √©tape par √©tape
   * sans refaire une g√©n√©ration compl√®te √† chaque correction.
   */
  public async *generateWithSelfCorrection(
    prompt: string,
    maxRecursions: number = 12
  ): AsyncGenerator<{ step: number, solution: string, reasoning: string }> {
    console.log("[TRMEngine] D√©marrage de la g√©n√©ration avec self-correction int√©gr√©e...");
    
    // Simule l'embedding du prompt
    const x = this.embed(prompt);
    let z = this.initLatent(); // "scratchpad" pour le raisonnement
    let y = this.initSolution();
    
    for (let step = 0; step < maxRecursions; step++) {
      // --- THINK: Le mod√®le "critique" sa r√©ponse actuelle ---
      z = await this.think(x, y, z);
      
      // --- ACT: Am√©liore la solution bas√©e sur la critique ---
      const newY = await this.act(y, z);
      
      // Decode pour streaming
      const currentSolution = this.decode(newY);
      const reasoning = this.decodeReasoning(z);
      
      yield {
        step,
        solution: currentSolution,
        reasoning // ‚úÖ Expose le "pourquoi" de chaque am√©lioration
      };
      
      // Halting condition (converged)
      if (this.hasConverged(y, newY)) {
        console.log(`[TRMEngine] Self-correction termin√©e √† l'√©tape ${step} (convergence atteinte)`);
        break;
      }
      
      y = newY;
    }
  }

  private embed(prompt: string): any {
    // Simule l'embedding du prompt
    return { embedded: prompt.substring(0, 10) + "..." };
  }

  private initLatent(): any {
    // Initialise l'espace latent pour le raisonnement ("scratchpad")
    return { thoughts: [], history: [] };
  }

  private initSolution(): any {
    // Initialise la solution
    return { content: "" };
  }

  private async think(x: any, y: any, z: any): Promise<any> {
    // Simule le processus de pens√©e avec critique int√©gr√©e
    await new Promise(r => setTimeout(r, 8)); // 8ms par √©tape (TRM l√©ger)
    
    // Ajoute la pens√©e courante √† l'historique
    const thought = `Thought at step ${z.thoughts.length}: Analyzing solution quality`;
    return { 
      ...z, 
      thoughts: [...z.thoughts, thought],
      history: [...z.history, { solution: y.content, thought }]
    };
  }

  private async act(y: any, z: any): Promise<any> {
    // Simule l'am√©lioration de la solution bas√©e sur la critique
    await new Promise(r => setTimeout(r, 8)); // 8ms par √©tape (TRM l√©ger)
    
    // Am√©liore progressivement la solution en s'appuyant sur l'historique
    const improvement = ` Improvement step ${z.thoughts.length} based on previous analysis`;
    return { 
      ...y, 
      content: y.content + improvement
    };
  }

  private decode(solution: any): string {
    // D√©code la solution pour le streaming
    return solution.content;
  }

  private decodeReasoning(latent: any): string {
    // D√©code le raisonnement
    return latent.thoughts[latent.thoughts.length - 1] || "Initial reasoning";
  }

  private hasConverged(oldY: any, newY: any): boolean {
    // Condition d'arr√™t : convergence bas√©e sur la stabilit√©
    return Math.random() < 0.15; // 15% de chance de converger √† chaque √©tape
  }
}
```

#### 3. Mise √† jour du TaskExecutor avec Int√©gration TRM et Suivi d'Am√©lioration
Le TaskExecutor devient le chef d'orchestre avec TRM comme moteur central, critique structur√©e et delta scoring.

```typescript
// src/core/kernel/TaskExecutor.ts (Mise √† jour majeure)

import { responseCritic, Critique } from './critics/ResponseCritic';
import { TRMEngine } from './engine/TRMEngine';
// ... (autres imports)

const MAX_CORRECTION_ATTEMPTS = 2;

class TaskExecutor {
  // ... (propri√©t√©s et executePlan existants)

  private async executeSingleTask(task: ExpertTask): Promise<TaskResult> {
    // D√©tecte si la t√¢che n√©cessite du raisonnement
    const requiresReasoning = this.detectReasoningTask(task.prompt);
    
    if (requiresReasoning) {
      // ‚úÖ Utilise TRM comme moteur central pour les t√¢ches complexes
      return this.executeWithTRM(task);
    }
    
    // Pour les t√¢ches simples, utilise l'approche avec critique comme backstop
    return this.executeSingleTaskWithCritic(task);
  }

  private detectReasoningTask(prompt: string): boolean {
    // D√©tecte si la t√¢che n√©cessite du raisonnement
    const reasoningKeywords = ['why', 'how', 'explain', 'reason', 'analyze', 'compare', 'evaluate', 'justify'];
    const lowerPrompt = prompt.toLowerCase();
    return reasoningKeywords.some(keyword => lowerPrompt.includes(keyword));
  }

  private async executeWithTRM(task: ExpertTask): Promise<TaskResult> {
    console.log(`[TaskExecutor] Ex√©cution avec TRM (moteur central) pour ${task.expert}`);
    
    const trmEngine = new TRMEngine();
    let finalSolution = "";
    let reasoningTrace = "";
    let stepCount = 0;
    
    // Stream les √©tapes de raisonnement √† l'utilisateur via SSE pour transparence
    console.log("[TaskExecutor] Streaming des √©tapes de raisonnement...");
    
    for await (const { step, solution, reasoning } of trmEngine.generateWithSelfCorrection(task.prompt)) {
      stepCount = step + 1;
      
      // Stream les √©tapes de raisonnement √† l'utilisateur
      console.log(`[Step ${step}] ${reasoning}`);
      
      // En production, cela serait envoy√© via SSE
      // sseStreamer.streamPartial(`[Step ${step}] ${reasoning}\n`);
      
      finalSolution = solution;
      reasoningTrace += `[Step ${step}] ${reasoning}\n`;
    }
    
    return {
      expert: 'reasoning-trm-7m',
      result: finalSolution,
      metadata: { 
        reasoningTrace,
        steps: stepCount,
        engine: 'TRM',
        mode: 'explain-reasoning'
      },
      status: 'success'
    };
  }

  private async executeSingleTaskWithCritic(task: ExpertTask): Promise<TaskResult> {
    let attempt = 0;
    let bestResponse = "";
    let bestScore = 0;
    let currentPrompt = task.prompt;

    while (attempt < MAX_CORRECTION_ATTEMPTS) {
      attempt++;
      console.log(`[TaskExecutor] Tentative de g√©n√©ration #${attempt} pour ${task.expert}`);
      
      // --- G√©n√©ration ---
      let generationResult = "";
      try {
        const engine = await runtimeManager.getEngineFor(task);
        for await (const token of engine.generate(currentPrompt, task.expert)) {
          generationResult += token;
        }
      } catch (error) {
        runtimeManager.handleFailure();
        throw error;
      }

      // --- Critique avec scoring d√©taill√© ---
      const critique = await responseCritic.review(task.prompt, generationResult);
      const currentScore = this.calculateGlobalScore(critique.scores);

      // ‚úÖ Suivi de l'am√©lioration par delta scoring
      const improvement = currentScore - bestScore;
      console.log(`[TaskExecutor] Tentative ${attempt}: score ${(currentScore * 100).toFixed(0)}% (${improvement > 0 ? '+' : ''}${(improvement * 100).toFixed(0)}%)`);

      if (currentScore > bestScore) {
        bestResponse = generationResult;
        bestScore = currentScore;
      }

      if (critique.is_acceptable) {
        console.log(`[TaskExecutor] ‚úÖ R√©ponse valid√©e √† la tentative #${attempt}.`);
        return {
          expert: task.expert,
          result: generationResult,
          metadata: {
            attempts: attempt,
            finalScore: currentScore,
            improvements: improvement,
            engine: 'MockEngine'
          },
          status: 'success'
        };
      }

      // --- Correction ---
      console.log(`[TaskExecutor] üîÑ Demande de correction. Raison: ${critique.reason}`);
      
      // Si le score baisse, arr√™te (pas d'am√©lioration) - delta scoring
      if (improvement < 0 && attempt > 1) {
        console.warn('[TaskExecutor] Score en baisse, utilisation de la meilleure r√©ponse pr√©c√©dente');
        return {
          expert: task.expert,
          result: bestResponse,
          metadata: { 
            attempts: attempt, 
            finalScore: bestScore,
            engine: 'MockEngine'
          },
          status: 'success'
        };
      }

      // Cr√©e un prompt structur√© avec balises XML pour guidage pr√©cis
      currentPrompt = this.buildStructuredCorrectionPrompt(task.prompt, generationResult, critique);
    }

    console.warn(`[TaskExecutor] √âchec de la validation apr√®s ${MAX_CORRECTION_ATTEMPTS} tentatives. Utilisation de la derni√®re r√©ponse g√©n√©r√©e.`);
    return {
      expert: task.expert,
      result: bestResponse,
      metadata: { 
        attempts: MAX_CORRECTION_ATTEMPTS, 
        finalScore: bestScore,
        status: 'max_attempts_reached',
        engine: 'MockEngine'
      },
      status: 'success_with_warnings'
    };
  }

  private calculateGlobalScore(scores: any): number {
    if (!scores) return 0;
    return Object.values(scores).reduce((a: number, b: number) => a + b, 0) / Object.keys(scores).length;
  }

  private buildStructuredCorrectionPrompt(
    originalPrompt: string,
    previousResponse: string,
    critique: Critique
  ): string {
    // Prompt de correction structur√© avec balises XML
    return `<task>
Am√©liore la r√©ponse suivante en te basant sur la critique.

<original_question>
${originalPrompt}
</original_question>

<previous_response>
${previousResponse}
</previous_response>

<critique>
Probl√®me: ${critique.reason}
Scores d√©taill√©s: ${JSON.stringify(critique.scores)}
Suggestion: ${critique.correction_suggestions}
</critique>

<instructions>
1. Garde ce qui √©tait bon dans la r√©ponse pr√©c√©dente
2. Corrige sp√©cifiquement le probl√®me: ${critique.reason}
3. Applique cette suggestion: ${critique.correction_suggestions}
4. Assure-toi de la clart√©, de l'exactitude et de l'exhaustivit√©
</instructions>

<improved_response>`;
  }
}

export const taskExecutor = new TaskExecutor();
```

## üéØ T√¢che #28 : Predictive Caching

### Objectif
Impl√©menter une logique de mise en cache pr√©dictive. Apr√®s avoir r√©pondu √† une question, le syst√®me doit :

1. G√©n√©rer 2 ou 3 questions de suivi probables.
2. Ex√©cuter ces questions en arri√®re-plan, de mani√®re silencieuse et avec une priorit√© basse.
3. Stocker les r√©ponses dans le ResponseCache.

Ainsi, lorsque l'utilisateur cliquera sur une suggestion de question de suivi, la r√©ponse sera d√©j√† pr√™te et s'affichera instantan√©ment.

### Philosophie "Usine Vide"
Nous allons modifier notre DialoguePlugin pour orchestrer ce processus. Nous utiliserons notre MockEngine pour simuler √† la fois la g√©n√©ration des questions de suivi et la g√©n√©ration de leurs r√©ponses.

### Sp√©cifications Techniques D√©taill√©es

#### 1. Cr√©ation du "G√©n√©rateur de Questions de Suivi" Contextuel et Intelligent

Ce service simulera la pr√©diction des prochaines questions de l'utilisateur avec une approche contextuelle, un scoring de confiance et une boucle de r√©troaction.

```typescript
// src/core/kernel/predictors/FollowUpPredictor.ts (Mise √† jour)

console.log("üîÆ FollowUpPredictor (Production) initialis√©.");

interface PredictedQuestion {
  question: string;
  confidence: number; // 0-1
  reasoning: string;
}

class FollowUpPredictor {
  private readonly QUESTION_PATTERNS = {
    'definition': [
      'Qu\'est-ce que {concept} exactement ?',
      'Peux-tu expliquer {concept} plus en d√©tail ?'
    ],
    'example': [
      'Peux-tu donner un exemple de {concept} ?',
      'Comment {concept} s\'applique-t-il dans la pratique ?'
    ],
    'comparison': [
      'Quelle est la diff√©rence entre {concept1} et {concept2} ?',
      'Pourquoi choisir {concept1} plut√¥t que {concept2} ?'
    ],
    'implementation': [
      'Comment impl√©menter {concept} ?',
      'Quels sont les pr√©-requis pour utiliser {concept} ?'
    ]
  };

  /**
   * G√©n√®re des questions de suivi contextuelles avec scoring de confiance.
   * Pr√©diction contextuelle + scoring + boucle de r√©troaction.
   */
  public async predict(prompt: string, response: string): Promise<PredictedQuestion[]> {
    console.log("[Predictor] Pr√©diction des questions de suivi...");
    await new Promise(r => setTimeout(r, 100)); // Simule le temps d'analyse

    const predictions: PredictedQuestion[] = [];
    const concepts = this.extractConcepts(response);
    const questionType = this.detectQuestionType(prompt);

    // Calcule une confiance pour chaque type de suivi
    if (concepts.length > 0) {
      predictions.push({
        question: `Peux-tu expliquer ${concepts[0]} plus en d√©tail ?`,
        confidence: 0.7, // Haute confiance : approfondissement est toujours pertinent
        reasoning: 'Approfondissement du concept principal'
      });
    }

    if (this.isTheoretical(response) && concepts.length > 0) {
      predictions.push({
        question: `Peux-tu donner un exemple de ${concepts[0]} ?`,
        confidence: 0.8, // Tr√®s haute : les exemples sont souvent demand√©s
        reasoning: 'R√©ponse th√©orique sans exemple'
      });
    }

    if (concepts.length >= 2) {
      predictions.push({
        question: `Quelle est la diff√©rence entre ${concepts[0]} et ${concepts[1]} ?`,
        confidence: 0.5, // Moyenne : pas toujours pertinent
        reasoning: 'Plusieurs concepts mentionn√©s'
      });
    }

    if (questionType === 'what' && concepts.length > 0) {
      predictions.push({
        question: `Comment impl√©menter ${concepts[0]} ?`,
        confidence: 0.6, // Moyenne-haute : souvent pertinent apr√®s d√©finition
        reasoning: 'Question "quoi" -> besoin d\'impl√©mentation'
      });
    }

    // Trie par confiance d√©croissante et limite √† 3
    return predictions.sort((a, b) => b.confidence - a.confidence).slice(0, 3);
  }

  private extractConcepts(text: string): string[] {
    // D√©tecte les noms propres, termes techniques, etc.
    const words = text.split(/\s+/);
    const concepts: string[] = [];

    // Pattern 1: Mots capitalis√©s (React, Python, Docker)
    const capitalizedWords = words.filter(w => 
      /^[A-Z][a-z]+/.test(w) && w.length > 3
    );
    concepts.push(...capitalizedWords);

    // Pattern 2: Mots entre guillemets
    const quotedTerms = text.match(/"([^"]+)"/g)?.map(q => q.replace(/"/g, '')) || [];
    concepts.push(...quotedTerms);

    // Pattern 3: Termes techniques (contiennent -, _, ou camelCase)
    const technicalTerms = words.filter(w => 
      /[a-z][A-Z]/.test(w) || w.includes('-') || w.includes('_')
    );
    concepts.push(...technicalTerms);

    // D√©duplique et limite
    return [...new Set(concepts)].slice(0, 5);
  }

  private detectQuestionType(prompt: string): 'what' | 'how' | 'why' | 'compare' | 'other' {
    const lower = prompt.toLowerCase();
    if (lower.startsWith('what') || lower.includes('qu\'est-ce')) return 'what';
    if (lower.startsWith('how') || lower.includes('comment')) return 'how';
    if (lower.startsWith('why') || lower.includes('pourquoi')) return 'why';
    if (lower.includes('difference') || lower.includes('vs')) return 'compare';
    return 'other';
  }

  private isTheoretical(response: string): boolean {
    // D√©tecte si la r√©ponse est th√©orique (pas d'exemples de code)
    const hasCodeExample = /```/.test(response) || /function|class|const/.test(response);
    return !hasCodeExample && response.length > 200;
  }
}

export const followUpPredictor = new FollowUpPredictor();
```

#### 2. Cr√©ation du Syst√®me de M√©triques pour le Predictive Caching Intelligent

Un syst√®me de tracking des performances du caching pr√©dictif avec boucle de r√©troaction adaptative.

```typescript
// src/core/kernel/cache/PredictiveCacheMetrics.ts (Mise √† jour)

console.log("üìä PredictiveCacheMetrics initialis√©.");

class PredictiveCacheMetrics {
  private predictions: Array<{
    question: string;
    confidence: number;
    timestamp: number;
    wasUsed: boolean;
    timeToUse?: number; // Temps avant utilisation
  }> = [];
  
  private readonly MAX_PREDICTIONS = 1000; // Limite de taille
  private confidenceThreshold = 0.6; // Seuil adaptatif

  public trackPrediction(question: string, confidence: number): void {
    // Garbage collection : retire les anciennes pr√©dictions
    if (this.predictions.length >= this.MAX_PREDICTIONS) {
      this.predictions = this.predictions.slice(this.MAX_PREDICTIONS / 2);
    }
    
    this.predictions.push({
      question,
      confidence,
      timestamp: Date.now(),
      wasUsed: false
    });
  }

  public trackCacheHit(question: string): void {
    const prediction = this.predictions.find(p => 
      this.isSimilar(p.question, question) && !p.wasUsed
    );

    if (prediction) {
      prediction.wasUsed = true;
      prediction.timeToUse = Date.now() - prediction.timestamp;
      console.log(`[Metrics] üéØ Cache hit ! Utilis√© apr√®s ${(prediction.timeToUse / 1000).toFixed(1)}s`);
      
      // Met √† jour le seuil adaptatif
      this.updateAdaptiveThreshold();
    }
  }

  public getStats(): {
    totalPredictions: number;
    hitRate: number;
    avgConfidence: number;
    avgTimeToUse: number;
    confidenceThreshold: number;
  } {
    const hits = this.predictions.filter(p => p.wasUsed);
    const usedPredictions = hits.filter(p => p.timeToUse !== undefined);

    return {
      totalPredictions: this.predictions.length,
      hitRate: this.predictions.length > 0 ? (hits.length / this.predictions.length) * 100 : 0,
      avgConfidence: this.predictions.length > 0 ? 
        this.predictions.reduce((sum, p) => sum + p.confidence, 0) / this.predictions.length : 0,
      avgTimeToUse: usedPredictions.length > 0 ?
        usedPredictions.reduce((sum, p) => sum + (p.timeToUse || 0), 0) / usedPredictions.length : 0,
      confidenceThreshold: this.confidenceThreshold
    };
  }

  private updateAdaptiveThreshold(): void {
    const stats = this.getStats();
    
    // Ajuste le seuil selon le hit rate
    if (stats.hitRate > 75) {
      // Hit rate √©lev√© : on peut descendre le seuil pour capturer plus de pr√©dictions
      this.confidenceThreshold = Math.max(0.4, this.confidenceThreshold - 0.05);
    } else if (stats.hitRate < 50) {
      // Hit rate faible : on monte le seuil pour √™tre plus s√©lectif
      this.confidenceThreshold = Math.min(0.8, this.confidenceThreshold + 0.05);
    }
    
    console.log(`[Metrics] Seuil de confiance mis √† jour: ${(this.confidenceThreshold * 100).toFixed(0)}%`);
  }

  private isSimilar(q1: string, q2: string): boolean {
    // D√©tecte si deux questions sont similaires (Levenshtein, cosine similarity, etc.)
    const normalized1 = q1.toLowerCase().replace(/[^\w\s]/g, '');
    const normalized2 = q2.toLowerCase().replace(/[^\w\s]/g, '');
    return normalized1 === normalized2; // Simpliste pour la demo
  }
  
  public getConfidenceThreshold(): number {
    return this.confidenceThreshold;
  }
}

export const cacheMetrics = new PredictiveCacheMetrics();
```

#### 3. Mise √† jour du ResponseCache avec TTL, GC et Limites

Am√©lioration du syst√®me de cache avec expiration automatique, garbage collection et limites.

```typescript
// src/core/kernel/cache/ResponseCache.ts (Mise √† jour)

interface CacheEntry {
  response: string;
  cachedAt: number;
  ttl: number; // Dur√©e de vie en ms
  metadata?: {
    confidence?: number;
    predictedAt?: number;
  };
}

class ResponseCache {
  private cache: Map<string, CacheEntry> = new Map();
  private readonly DEFAULT_TTL = 5 * 60 * 1000; // 5 minutes
  private readonly MAX_ENTRIES = 100; // Limite de taille
  private readonly GC_INTERVAL = 60 * 1000; // 1 minute
  private gcTimer: NodeJS.Timeout | null = null;

  constructor() {
    // Lance le garbage collector p√©riodique
    this.startGarbageCollection();
  }

  public set(
    prompt: string, 
    modelKey: string, 
    response: string,
    metadata?: any
  ): void {
    // Garbage collection si n√©cessaire
    if (this.cache.size >= this.MAX_ENTRIES) {
      this.performGarbageCollection();
    }
    
    const entry: CacheEntry = {
      response,
      cachedAt: Date.now(),
      // ‚úÖ TTL adaptatif : plus la confiance est haute, plus on garde longtemps
      ttl: metadata?.confidence 
        ? this.DEFAULT_TTL * metadata.confidence 
        : this.DEFAULT_TTL,
      metadata
    };

    this.cache.set(this.getCacheKey(prompt, modelKey), entry);
  }

  public get(prompt: string, modelKey?: string): string | null {
    const entry = this.cache.get(this.getCacheKey(prompt, modelKey));
    
    if (!entry) return null;

    // ‚úÖ V√©rifie l'expiration
    const age = Date.now() - entry.cachedAt;
    if (age > entry.ttl) {
      console.log(`[Cache] Entry expired (${(age / 1000).toFixed(0)}s old)`);
      this.cache.delete(this.getCacheKey(prompt, modelKey));
      return null;
    }

    return entry.response;
  }

  private getCacheKey(prompt: string, modelKey?: string): string {
    return `${prompt}::${modelKey || 'default'}`;
  }

  private startGarbageCollection(): void {
    this.gcTimer = setInterval(() => {
      this.performGarbageCollection();
    }, this.GC_INTERVAL);
  }

  private performGarbageCollection(): void {
    const now = Date.now();
    let expiredCount = 0;
    
    for (const [key, entry] of this.cache.entries()) {
      const age = now - entry.cachedAt;
      if (age > entry.ttl) {
        this.cache.delete(key);
        expiredCount++;
      }
    }
    
    if (expiredCount > 0) {
      console.log(`[Cache] Garbage collection: ${expiredCount} entr√©es expir√©es supprim√©es`);
    }
    
    // Si trop d'entr√©es, supprime les plus anciennes (LRU)
    if (this.cache.size > this.MAX_ENTRIES) {
      const entriesToDelete = this.cache.size - this.MAX_ENTRIES;
      const sortedEntries = Array.from(this.cache.entries())
        .sort((a, b) => a[1].cachedAt - b[1].cachedAt)
        .slice(0, entriesToDelete);
      
      for (const [key] of sortedEntries) {
        this.cache.delete(key);
      }
      
      console.log(`[Cache] LRU eviction: ${entriesToDelete} entr√©es supprim√©es`);
    }
  }

  public getStats(): { size: number, maxSize: number } {
    return {
      size: this.cache.size,
      maxSize: this.MAX_ENTRIES
    };
  }
}

export const responseCache = new ResponseCache();
```

#### 4. Mise √† jour du DialoguePlugin pour le Caching Pr√©dictif Intelligent avec Backpressure

Le DialoguePlugin devient le chef d'orchestre de cette strat√©gie d'anticipation avec toutes les am√©liorations.

```typescript
// src/core/plugins/DialoguePlugin.ts (Mise √† jour majeure)

import { followUpPredictor } from '../kernel/predictors/FollowUpPredictor';
import { cacheMetrics } from '../kernel/cache/PredictiveCacheMetrics';
// ... (autres imports)

class DialoguePlugin {
  // File de pr√©dictions avec backpressure
  private predictionQueue: Array<{
    question: string;
    confidence: number;
    reasoning: string;
    timestamp: number;
  }> = [];
  
  private readonly MAX_CONCURRENT_PREDICTIONS = 3;
  private readonly MAX_QUEUE_SIZE = 3; // File born√©e stricte
  private activePredictions = 0;

  // ... (process et processStream existants)

  /**
   * Orchestre le processus de r√©ponse principal et lance le caching pr√©dictif.
   */
  public async handleUserPrompt(prompt: string): Promise<void> {
    try {
      // Ex√©cute le plan principal pour r√©pondre √† la question de l'utilisateur
      const plan = await router.createPlan(prompt);
      const results = await taskExecutor.executePlan(plan);
      const finalResponse = await fusioner.fuse(results);
      const sanitizedResponse = guardrails.sanitizeOutput(finalResponse);
      const watermarkedResponse = watermarkingService.apply(sanitizedResponse);

      // Stream la r√©ponse finale √† l'UI
      sseStreamer.streamComplete(watermarkedResponse);
      responseCache.set(prompt, plan.tasks[0].expert, watermarkedResponse);

      // LANCE LE CACHING PR√âDICTIF en arri√®re-plan
      this.runPredictiveCaching(prompt, watermarkedResponse);

    } catch (error) {
      sseStreamer.streamError(error as Error);
    }
  }

  /**
   * G√©n√®re et met en cache les r√©ponses aux questions de suivi probables.
   * C'est une op√©ration "fire-and-forget" de basse priorit√© avec backpressure.
   */
  private async runPredictiveCaching(originalPrompt: string, originalResponse: string): Promise<void> {
    console.log("[PredictiveCache] D√©marrage du caching pr√©dictif...");
    
    // 1. Pr√©dire les questions de suivi avec scoring de confiance
    const predictions = await followUpPredictor.predict(originalPrompt, originalResponse);
    
    // ‚úÖ Ne cache que les questions avec confiance ‚â• 0.6
    const threshold = 0.6; // Seuil fixe selon les sp√©cifications
    const worthCaching = predictions.filter(p => p.confidence >= threshold);
    
    if (worthCaching.length === 0) {
      console.log(`[PredictiveCache] Aucune question avec confiance ‚â• ${(threshold * 100).toFixed(0)}%`);
      return;
    }

    // 2. Ajoute les pr√©dictions √† la file avec backpressure
    for (const { question, confidence, reasoning } of worthCaching) {
      // Gestion de la backpressure stricte
      if (this.predictionQueue.length >= this.MAX_QUEUE_SIZE) {
        console.log("[PredictiveCache] File pleine, suppression des pr√©dictions les plus anciennes (OLDEST)");
        this.predictionQueue.shift(); // Supprime la plus ancienne (strat√©gie OLDEST)
      }
      
      this.predictionQueue.push({
        question,
        confidence,
        reasoning,
        timestamp: Date.now()
      });
    }
    
    // 3. Traite la file
    this.processPredictionQueue();
  }

  private async processPredictionQueue(): Promise<void> {
    // Backpressure : limite le nombre de pr√©dictions concurrentes
    while (this.activePredictions < this.MAX_CONCURRENT_PREDICTIONS && this.predictionQueue.length > 0) {
      const prediction = this.predictionQueue.shift();
      if (!prediction) continue;
      
      this.activePredictions++;
      
      // Ex√©cute la pr√©diction en parall√®le
      this.executePrediction(prediction)
        .finally(() => {
          this.activePredictions--;
          // Continue √† traiter la file
          if (this.predictionQueue.length > 0) {
            this.processPredictionQueue();
          }
        });
    }
  }

  private async executePrediction(prediction: { question: string, confidence: number, reasoning: string, timestamp: number }): Promise<void> {
    const { question, confidence, reasoning } = prediction;
    
    try {
      console.log(`[PredictiveCache] Pr√©-calcul de la r√©ponse pour: "${question.substring(0, 40)}..."`);
      
      // ‚úÖ Track la pr√©diction pour les m√©triques
      cacheMetrics.trackPrediction(question, confidence);
      
      // Cr√©e un plan avec une priorit√© basse
      const plan = await router.createPlan(question);
      plan.tasks.forEach(t => t.priority = 'BACKGROUND'); // Marque comme t√¢che de fond
      
      const results = await taskExecutor.executePlan(plan);
      const finalResponse = await fusioner.fuse(results);
      
      // Met en cache la r√©ponse avec m√©tadonn√©es
      responseCache.set(question, plan.tasks[0].expert, finalResponse, {
        confidence,
        predictedAt: Date.now(),
        reasoning
      });
      
      console.log(`[PredictiveCache] ‚úÖ R√©ponse pour "${question.substring(0, 40)}..." mise en cache.`);

    } catch (error) {
      console.warn(`[PredictiveCache] √âchec du pr√©-calcul pour une question.`, error);
    }
  }
}

export const dialoguePlugin = new DialoguePlugin();
```

### R√©sultats Attendus
1. Cr√©ation du module ResponseCritic avec √©valuation structur√©e multi-dimensionnelle
2. Cr√©ation du moteur TRMEngine comme moteur central d'auto-correction int√©grant g√©n√©ration ET critique
3. Mise √† jour du TaskExecutor avec TRM comme moteur central, critique structur√©e et suivi d'am√©lioration
4. Impl√©mentation d'une boucle d'it√©ration avec tracking d'am√©lioration (delta scoring)
5. Architecture modulaire permettant de remplacer les composants factices
6. Am√©lioration de la qualit√© des r√©ponses g√©n√©r√©es avec rapidit√© quasi-instantan√©e
7. Contr√¥le qualit√© interne avant envoi √† l'utilisateur
8. Journalisation des tentatives de correction pour suivi et am√©lioration
9. Exposition du processus de raisonnement √† l'utilisateur via streaming pour transparence
10. Int√©gration optimale avec TRM pour une correction ultra-rapide (96ms vs plusieurs secondes)
11. Utilisation du critique structur√© comme backstop ou pour audit externe
12. Impl√©mentation de prompts structur√©s avec balises XML pour un guidage pr√©cis
13. Mode "explain reasoning" pour traces de raisonnement √† des usages avanc√©s
14. Cr√©ation du module FollowUpPredictor pour la pr√©diction contextuelle des questions de suivi
15. Mise √† jour du DialoguePlugin pour orchestrer le caching pr√©dictif intelligent
16. Ex√©cution en arri√®re-plan des r√©ponses aux questions de suivi probables avec scoring de confiance
17. Stockage des r√©ponses pr√©dites dans le cache avec TTL adaptatif
18. Syst√®me de m√©triques pour le tracking du hit rate et de la performance
19. Filtrage des pr√©dictions par seuil de confiance fixe (‚â• 0.6)
20. M√©tadonn√©es enrichies pour chaque entr√©e de cache
21. Garbage collection p√©riodique pour maintenir le cache sain
22. Limites de taille avec strat√©gie LRU pour √©viter la saturation m√©moire
23. Backpressure stricte avec file born√©e (3 max) et strat√©gie OLDEST
24. Boucle de r√©troaction adaptative qui ajuste le seuil de confiance selon les performances
25. Suggestions UI branch√©es sur le m√™me pr√©dicteur pour affichage des follow-ups