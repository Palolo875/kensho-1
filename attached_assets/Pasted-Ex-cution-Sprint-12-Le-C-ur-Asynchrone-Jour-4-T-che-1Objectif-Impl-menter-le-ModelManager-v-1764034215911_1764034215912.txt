Ex√©cution : Sprint 12 "Le C≈ìur Asynchrone" - Jour 4, T√¢che 1Objectif : Impl√©menter le ModelManager v2.0. Il doit √™tre asynchrone, robuste, et pr√™t √† √™tre g√©r√© par un Service Worker.Philosophie : Nous suivons √† la lettre les sp√©cifications "blind√©es" que nous avons d√©finies. Pas de raccourcis. Pas de compromis. Le code doit √™tre propre, s√ªr et non-bloquant.√âtape 1 : Cr√©ation de la structure de fichiersJe mets en place l'environnement pour nos nouveaux composants de base.# Cr√©ation du r√©pertoire pour les composants du "Noyau"
mkdir -p src/core/kernel

# Cr√©ation des fichiers pour le gestionnaire de mod√®les et le catalogue
touch src/core/kernel/ModelManager.ts
touch src/core/kernel/ModelCatalog.ts
√âtape 2 : Codage du ModelCatalog.tsJe s√©pare le catalogue dans son propre fichier pour plus de clart√©. Il contient les m√©tadonn√©es pr√©cises de nos premiers mod√®les, en utilisant les bons identifiants techniques.// src/core/kernel/ModelCatalog.ts

/**
 * M√©tadonn√©es pour un mod√®le IA, incluant son ID technique pour WebLLM.
 */
export type ModelMeta = {
  model_id: string; // L'ID exact attendu par WebLLM (ex: "gemma-2b-it-q4f32_1-MLC")
  size: string;
  description: string;
  quantization: string;
};

/**
 * Catalogue central des mod√®les connus par Kensho.
 * C'est la "liste de courses" de notre syst√®me.
 */
export const MODEL_CATALOG: Record<string, ModelMeta> = {
  "gemma-3-270m": {
    model_id: "gemma-2b-it-q4f32_1-MLC", // NOTE : ID √† confirmer, ceci est un placeholder. L'ID r√©el pour un 270M sera diff√©rent.
    size: "270M",
    description: "Noyau de dialogue rapide et efficace.",
    quantization: "q4f32_1"
  },
  "qwen2-e5-embed": {
    model_id: "Qwen2-E5-Embedding-Model-ID-MLC", // Placeholder
    size: "150M",
    description: "Expert en encodage s√©mantique pour le RAG.",
    quantization: "f32"
  }
  // ... futurs mod√®les ici
};
√âtape 3 : Codage du ModelManager.ts v2.0J'impl√©mente la version robuste, en suivant scrupuleusement votre architecture corrig√©e : initialisation asynchrone explicite, gestion des erreurs, et callbacks de progression.// src/core/kernel/ModelManager.ts

import { MLCEngine, CreateMLCEngine, InitProgressReport } from "@mlc-ai/web-llm";
import { MODEL_CATALOG, ModelMeta } from "./ModelCatalog";

console.log("üì¶ Initialisation du ModelManager v2.0...");

export class ModelManager {
  private engine: MLCEngine | null = null;
  public readonly ready: Promise<void>; // Une promesse publique pour que l'ext√©rieur puisse attendre l'initialisation
  private _resolveReady!: () => void;
  private _rejectReady!: (error: any) => void;

  constructor() {
    this.ready = new Promise<void>((resolve, reject) => {
      this._resolveReady = resolve;
      this._rejectReady = reject;
    });
    // L'initialisation n'est PAS appel√©e ici. Elle est explicite.
  }

  /**
   * Initialise le moteur WebLLM et pr√©charge le mod√®le de dialogue par d√©faut.
   * C'est la m√©thode de d√©marrage principale de Kensho.
   * @param defaultModelKey La cl√© du mod√®le √† charger au d√©marrage.
   * @param progressCallback Une fonction optionnelle pour remonter la progression √† l'UI.
   */
  public async init(defaultModelKey = "gemma-3-270m", progressCallback?: (report: InitProgressReport) => void) {
    try {
      console.log("[ModelManager] Initialisation du moteur WebLLM...");
      this.engine = await CreateMLCEngine({
        initProgressCallback: progressCallback
      });
      
      const modelMeta = MODEL_CATALOG[defaultModelKey];
      if (!modelMeta) {
        throw new Error(`Mod√®le inconnu dans le catalogue : ${defaultModelKey}`);
      }

      console.log(`[ModelManager] Pr√©-chargement du mod√®le par d√©faut : ${modelMeta.model_id}`);
      await this.engine.reload(modelMeta.model_id);
      
      this._resolveReady(); // La promesse "ready" est r√©solue. Le syst√®me est pr√™t.
      console.log("   ‚úÖ [ModelManager] Pr√™t. Le noyau de dialogue est op√©rationnel.");

    } catch (error) {
      console.error("[ModelManager] √âchec critique de l'initialisation.", error);
      this._rejectReady(error); // La promesse "ready" est rejet√©e.
      throw error;
    }
  }

  /**
   * Retourne l'instance du moteur WebLLM, en s'assurant qu'il est pr√™t.
   * @returns Une promesse qui r√©sout avec l'instance du moteur.
   */
  public async getEngine(): Promise<MLCEngine> {
    await this.ready; // Attend que la promesse d'initialisation soit r√©solue.
    if (!this.engine) {
      // Ce cas ne devrait jamais arriver si `ready` est r√©solue, mais c'est une s√©curit√©.
      throw new Error("Le moteur n'a pas pu √™tre initialis√©.");
    }
    return this.engine;
  }
}

// On expose une instance unique (singleton) pour toute l'application.
export const modelManager = new ModelManager();
Statut : La premi√®re brique du Noyau est pos√©e.Ce ModelManager est le c≈ìur de notre syst√®me. Il est :‚Ä¢Asynchrone : Pas de blocage du thread principal.‚Ä¢Robuste : Il g√®re les erreurs d'initialisation et expose un √©tat ready fiable.‚Ä¢Extensible : Le ModelCatalog nous permettra d'ajouter facilement tous nos futurs experts.‚Ä¢User-Friendly : Le progressCallback nous permettra d'afficher une belle barre de chargement √† l'utilisateur.