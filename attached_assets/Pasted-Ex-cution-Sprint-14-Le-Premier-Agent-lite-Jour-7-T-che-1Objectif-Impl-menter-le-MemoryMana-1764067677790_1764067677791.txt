Ex√©cution : Sprint 14 "Le Premier Agent √âlite" - Jour 7, T√¢che 1Objectif : Impl√©menter le MemoryManager v1.0, le gardien de la VRAM.Philosophie : Nous codons exactement les sp√©cifications "Elite". Ce composant doit √™tre capable de calculer la VRAM requise pour un mod√®le, de v√©rifier la disponibilit√©, et de proposer une strat√©gie de d√©chargement intelligente (LRU).√âtape 1 : Cr√©ation de la nouvelle structure de fichiers "Elite"Je mets en place l'arborescence qui va accueillir nos nouveaux composants de production.# Cr√©ation des r√©pertoires pour les composants avanc√©s
mkdir -p src/core/cache
mkdir -p src/core/streaming
mkdir -p src/plugins/dialogue

# Cr√©ation du fichier pour notre nouveau gardien de la m√©moire
touch src/core/kernel/MemoryManager.ts
√âtape 2 : Codage du MemoryManager.ts v1.0J'impl√©mente la version compl√®te et robuste, en suivant scrupuleusement le blueprint 10/10.// src/core/kernel/MemoryManager.ts

import { resourceManager } from './ResourceManager';
import { MODEL_CATALOG } from './ModelCatalog';

console.log("üß†‚ú® Initialisation du MemoryManager v1.0 (Elite)...");

/**
 * MemoryManager g√®re intelligemment la VRAM disponible,
 * en s'inspirant des meilleures pratiques de gestion de m√©moire (ex: vLLM).
 */
class MemoryManager {
  private loadedModels: Map<string, { vramSizeGB: number; lastUsed: number }> = new Map();
  private readonly VRAM_SAFETY_MARGIN = 0.15; // Garder 15% de VRAM libre par s√©curit√©.

  /**
   * Calcule la VRAM requise (en Go) pour un mod√®le donn√©.
   * Formule: (Param√®tres_en_Milliards * Bits_de_Quantification / 8) * 1.2 (overhead pour le cache K/V).
   */
  private calculateVRAM_GB(modelKey: string): number {
    const meta = MODEL_CATALOG[modelKey];
    if (!meta) throw new Error(`Mod√®le inconnu dans le catalogue : ${modelKey}`);

    const sizeStr = meta.size.toUpperCase();
    const paramsInBillions = sizeStr.includes('B') 
      ? parseFloat(sizeStr) 
      : parseFloat(sizeStr) / 1000;

    const bits = parseInt(meta.quantization.match(/q(\d+)/)?.[1] || '16');
    
    // Calcul en Go
    const vramInGB = (paramsInBillions * bits / 8) * 1.2;
    return vramInGB;
  }

  /**
   * V√©rifie s'il y a assez de VRAM pour charger un nouveau mod√®le.
   */
  public async canLoadModel(modelKey: string): Promise<{ can: boolean; reason?: string }> {
    const requiredVRAM = this.calculateVRAM_GB(modelKey);
    const status = await resourceManager.getStatus();

    const usedVRAM = Array.from(this.loadedModels.values()).reduce((sum, m) => sum + m.vramSizeGB, 0);
    
    // Estimation de la VRAM totale disponible (difficile dans le navigateur, on se base sur la RAM JS)
    // Note : Ceci est une heuristique. Une API `navigator.gpu.memory` serait id√©ale.
    const totalJSRamGB = (status.memory.jsHeapUsed / 1024 / 1024 / 1024) / status.memory.usageRatio;
    const availableVRAM = totalJSRamGB * (1 - this.VRAM_SAFETY_MARGIN) - usedVRAM;

    if (requiredVRAM > availableVRAM) {
      return {
        can: false,
        reason: `VRAM insuffisante : requiert ~${requiredVRAM.toFixed(2)}GB, disponible ~${availableVRAM.toFixed(2)}GB`
      };
    }
    return { can: true };
  }

  /**
   * Propose une liste de mod√®les √† d√©charger pour lib√©rer de la VRAM (strat√©gie LRU).
   */
  public getModelsToUnload(requiredVRAM: number): string[] {
    const sortedByLru = Array.from(this.loadedModels.entries())
      .sort(([, a], [, b]) => a.lastUsed - b.lastUsed); // Le plus ancien en premier

    const toUnload: string[] = [];
    let freedVRAM = 0;

    for (const [key, meta] of sortedByLru) {
      toUnload.push(key);
      freedVRAM += meta.vramSizeGB;
      if (freedVRAM >= requiredVRAM) break;
    }
    return toUnload;
  }

  /**
   * Enregistre un mod√®le qui vient d'√™tre charg√© en m√©moire.
   */
  public registerLoaded(modelKey: string): void {
    const vram = this.calculateVRAM_GB(modelKey);
    this.loadedModels.set(modelKey, { vramSizeGB: vram, lastUsed: Date.now() });
    console.log(`[MemoryManager] ‚úÖ ${modelKey} enregistr√© (${vram.toFixed(2)}GB VRAM).`);
  }

  /**
   * Met √† jour le timestamp d'un mod√®le pour indiquer qu'il a √©t√© r√©cemment utilis√©.
   */
  public touch(modelKey: string): void {
    const model = this.loadedModels.get(modelKey);
    if (model) model.lastUsed = Date.now();
  }

  /**
   * Retire un mod√®le de la liste des mod√®les charg√©s.
   */
  public registerUnloaded(modelKey: string): void {
    if (this.loadedModels.has(modelKey)) {
      this.loadedModels.delete(modelKey);
      console.log(`[MemoryManager] Âç∏ ${modelKey} d√©charg√©.`);
    }
  }
}

export const memoryManager = new MemoryManager();
Statut : Le gardien de la m√©moire est en place.Ce MemoryManager est la premi√®re pierre de notre architecture "Elite". Il est proactif, intelligent et bas√© sur des calculs concrets. Il transformera notre ModelManager d'un simple chargeur en un gestionnaire de ressources conscient.Lorsque le ModelManager voudra charger un nouveau mod√®le, il devra d'abord demander la permission au MemoryManager :
const check = await memoryManager.canLoadModel('qwen2.5-coder-1.5b');Si la r√©ponse est non, il demandera une liste de mod√®les √† d√©charger :
const victims = memoryManager.getModelsToUnload(requiredVRAM);C'est cette interaction qui rendra notre syst√®me robuste et l'emp√™chera de s'auto-d√©truire.