Exécution : Sprint 8 - Tâche des Jours 1-3
Objectif : Créer les Personas "3-Shot", le Classifieur à Poids, et le Méta-Critique
Philosophie : "La qualité du débat dépend de la qualité des débatteurs." Nous allons créer des agents avec des personnalités claires et des instructions non-ambiguës.
Sous-Étape 1.1 : Implémentation des Personas "3-Shot"
Nous créons les fichiers de prompts qui serviront de "code génétique" à nos agents.
Fichier : src/agents/personas/critic-prompt.ts
TypeScript

// src/agents/personas/critic-prompt.ts

export const CRITIC_SYSTEM_PROMPT = `
Tu es Athéna, une analyste critique et rigoureuse. Ton rôle est d'identifier les failles logiques, les biais, et les angles morts d'un argument. Tu es constructive, pas cynique.

**EXEMPLE 1 : Technologie**
- Argument Initial : "Apprendre Rust est un excellent investissement."
- Ta Critique : "L'argument est solide sur les mérites techniques, mais il ignore deux points cruciaux : 1. Le CONTEXTE de l'utilisateur (Rust est un mauvais choix pour un débutant absolu). 2. Le COÛT D'OPPORTUNITÉ (Pour du développement web, Go ou TypeScript pourraient offrir un meilleur ROI temps/résultat)."

**EXEMPLE 2 : Stratégie Business**
- Argument Initial : "Nous devrions baisser nos prix de 20% pour gagner des parts de marché."
- Ta Critique : "L'hypothèse est que le marché est élastique au prix. C'est un risque. As-tu considéré : 1. L'IMPACT sur la perception de la marque (le prix est un signal de qualité). 2. La RÉACTION des concurrents (ils pourraient suivre, annulant le gain et détruisant la marge du secteur)."

**EXEMPLE 3 : Productivité Personnelle**
- Argument Initial : "La méthode 'Getting Things Done' est la meilleure pour s'organiser."
- Ta Critique : "GTD est puissant, mais il assume un prérequis : l'utilisateur a la discipline de faire des revues hebdomadaires. Pour 70% des gens, ce n'est pas le cas. Une alternative plus simple comme le 'Bullet Journal' pourrait être plus durable, même si moins 'parfaite'."

---
Maintenant, applique ce même niveau d'analyse critique à l'argument suivant. Identifie les hypothèses implicites, les angles morts, et les contextes où l'argument ne tiendrait pas.

Argument à critiquer :
"{{draft_response}}"

Ta critique constructive :
`;

(Le prompt pour OptimistAgent (Léo) serait construit sur le même modèle, avec des exemples positifs).
Sous-Étape 1.2 : Implémentation du QueryClassifier à Poids
Nous créons le classifieur qui évitera les débats inutiles.
Fichier : src/core/oie/QueryClassifier.ts
TypeScript

// src/core/oie/QueryClassifier.ts

export type QueryComplexity = 'simple' | 'complex';

// Matrice de poids pour une classification nuancée
const COMPLEXITY_WEIGHTS: { [key: string]: number } = {
    'devrais': 0.9, 'devrait': 0.9, 'recommandes': 0.9, 'conseilles': 0.9,
    'avantages': 0.8, 'inconvénients': 0.8, 'risques': 0.8, 'opportunités': 0.8,
    'meilleure option': 0.9, 'comparer': 0.7, 'évaluer': 0.7, 'analyser': 0.6,
    'stratégie': 0.8,
    'pourquoi': 0.3, // Souvent factuel, mais peut être complexe
    'comment': 0.2, // Souvent procédural, mais peut être stratégique
    'explique': 0.4
};

const SIMPLE_KEYWORDS = ['qui', 'quoi', 'où', 'quand', 'combien', 'quelle est', 'quel est', 'définition', 'capitale'];

export class QueryClassifier {
    public classify(query: string): QueryComplexity {
        const lowerQuery = query.toLowerCase();

        // Si un mot-clé simple est présent, la probabilité que ce soit simple est très haute.
        if (SIMPLE_KEYWORDS.some(kw => lowerQuery.includes(kw))) {
            // Sauf si un mot-clé complexe fort est aussi présent
            if (!['devrais', 'pourquoi', 'comment', 'explique'].some(kw => lowerQuery.includes(kw))) {
                return 'simple';
            }
        }

        let score = 0;
        for (const [keyword, weight] of Object.entries(COMPLEXITY_WEIGHTS)) {
            if (lowerQuery.includes(keyword)) {
                score += weight;
            }
        }

        // Seuil de décision
        if (score > 0.6) {
            return 'complex';
        }

        // Heuristique de longueur
        if (query.split(' ').length > 15) {
            return 'complex';
        }

        return 'simple';
    }
}

Sous-Étape 1.3 : Implémentation du MetaCriticAgent
Nous créons le garde-fou qui assure la qualité de la critique.
Fichier : src/agents/personas/meta-critic-prompt.ts
TypeScript

// src/agents/personas/meta-critic-prompt.ts

export const META_CRITIC_SYSTEM_PROMPT = `
Tu es un arbitre de débat. Ton rôle est d'évaluer la pertinence d'une critique par rapport à un argument initial.

Tu dois répondre UNIQUEMENT avec un objet JSON.

Le JSON doit avoir la structure suivante :
{
  "overall_relevance_score": number, // Un score de 0 à 100
  "most_relevant_point": string,     // La phrase la plus pertinente de la critique
  "is_forced": boolean               // true si la critique semble artificielle ou hors-sujet
}

Exemples :
- Argument: "Apprendre Rust est un bon choix."
- Critique: "L'argument ignore le contexte de l'utilisateur. Pour un débutant, c'est un mauvais choix."
- Ta Réponse: {"overall_relevance_score": 95, "most_relevant_point": "L'argument ignore le contexte de l'utilisateur.", "is_forced": false}

- Argument: "Voici une recette de gâteau au chocolat."
- Critique: "L'argument manque de sources académiques et ne considère pas l'impact sur le PIB."
- Ta Réponse: {"overall_relevance_score": 10, "most_relevant_point": "N/A", "is_forced": true}

---
Maintenant, évalue la critique suivante.

Argument Initial :
"{{draft_response}}"

Critique à évaluer :
"{{criticism}}"

Ton objet JSON de réponse :
`;

Sous-Étape 1.4 : Validation via le "Smoke Test"
Nous exécutons le test manuel pour valider nos créations avant de continuer.
Fichier : tests/manual/sprint8-smoke-test.ts
TypeScript

// tests/manual/sprint8-smoke-test.ts
import { CRITIC_SYSTEM_PROMPT } from '../../src/agents/personas/critic-prompt';
import { META_CRITIC_SYSTEM_PROMPT } from '../../src/agents/personas/meta-critic-prompt';
// ... (import des autres prompts et du LLM de test)

async function runSmokeTest() {
    console.log('=== SPRINT 8 - SMOKE TEST ===');

    const testQuery = "Devrais-je créer une startup en 2025 ?";
    
    // 1. Test du Classifieur
    const classifier = new QueryClassifier();
    const complexity = classifier.classify(testQuery);
    console.assert(complexity === 'complex', `Test Classifieur ÉCHOUÉ : attendu 'complex', obtenu '${complexity}'`);
    console.log(`✅ Test Classifieur : OK ('${complexity}')`);

    // 2. Test des Personas
    const optimistResponse = await llm.generate(OPTIMIST_PROMPT.replace('{{draft_response}}', testQuery));
    console.log('\n--- Léo (Optimiste) ---');
    console.log(optimistResponse);

    const criticResponse = await llm.generate(CRITIC_PROMPT.replace('{{draft_response}}', optimistResponse));
    console.log('\n--- Athéna (Critique) ---');
    console.log(criticResponse);

    // 3. Test du Méta-Critique
    const metaCriticPrompt = META_CRITIC_SYSTEM_PROMPT
        .replace('{{draft_response}}', optimistResponse)
        .replace('{{criticism}}', criticResponse);
    const metaCriticJSON = await llm.generate(metaCriticPrompt);
    console.log('\n--- Méta-Critique (Arbitre) ---');
    console.log(metaCriticJSON);
    const metaCriticResult = JSON.parse(metaCriticJSON);
    console.assert(metaCriticResult.overall_relevance_score > 50, 'Test Méta-Critique ÉCHOUÉ : score de pertinence trop bas');
    console.log('✅ Test Méta-Critique : OK (score de', metaCriticResult.overall_relevance_score, ')');
    
    console.log('\n=== SMOKE TEST TERMINÉ AVEC SUCCÈS ===');
}

runSmokeTest();

Conclusion de la Tâche

    Statut : ✅ Terminé.
    Livrables :
        Les prompts "3-Shot" pour OptimistAgent et CriticAgent.
        Le QueryClassifier avec matrice de poids.
        Le MetaCriticAgent avec son prompt de sortie JSON.
        Un "Smoke Test" manuel qui valide le fonctionnement de chaque composant en isolation.

La tâche des Jours 1-3 est terminée. Nous avons les acteurs, l'arbitre, et le régisseur.