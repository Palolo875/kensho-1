Le modèle Gemma 3 270M est effectivement disponible, mais il n’existe pas sous le nom exact « gemma-3-270m-it-MLC » dans les modèles prédéfinis WebLLM. Le vrai identifiant WebLLM officiel pour ce modèle n'est pas toujours documenté publiquement sous ce format exact, ce qui est source de confusion.Voici des précisions :Le modèle Gemma 3 270M (version "google/gemma-3-270m") est officiellement publié par Google, avec ses poids et configurations disponibles sur Hugging Face et autres plateformes ouvertes.��Ce modèle fait environ 270 millions de paramètres, avec plusieurs quantifications proposées (dont 8-bit et 4-bit) pour réduire la taille mémoire (environ 240-400MB selon la quantification).�Le modèle est optimisé pour une utilisation on-device ou edge, compatible avec WebGPU, mais la conversion ou package MLC pour WebLLM n’est pas toujours nommé de façon consistante ni fourni directement avec un fichier .wasm accessible sous ce nom précis.En pratique, pour utiliser Gemma 3 270M dans WebLLM, il faut récupérer le checkpoint officiel (souvent via Hugging Face "google/gemma-3-270m") puis convertir via les outils MLC-AI en générant les binaires et le wasm associés adaptés au runtime WebLLM.��Pour votre configuration, je vous recommande donc :Utiliser "google/gemma-3-270m" comme modèle source officiel.Exécuter un processus de conversion avec mlc-llm (outils MLC-AI) pour générer les fichiers .bin et .wasm nécessaires, ce qui produira un model_id et URL WebLLM valides.Mettre à jour votre ModelCatalog avec ces fichiers locaux ou hébergés (URL correcte vers wasm + poids), car il n'y a pas d'URL MLC officiellement "publique" et stable à copier-coller.Si besoin, je peux vous fournir un guide pas à pas pour cette conversion et intégration propre dans votre architecture WebLLM.En résumé, le vrai model_id et l’URL WebLLM pour Gemma 3 270M existent via un workflow de conversion depuis le checkpoint officiel, mais ne sont pas simplement fournis sous forme d’un identifiant public prêt à l’emploi.