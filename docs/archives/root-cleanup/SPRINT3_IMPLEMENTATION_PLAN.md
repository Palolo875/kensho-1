# üéØ Sprint 3 : Plan d'Impl√©mentation D√©taill√©

**Date de d√©but** : 2025-11-21  
**Objectif** : Transformer Kensho en assistant agentique complet avec LLM r√©el, tests robustes, et m√©moire long-terme

---

## üìã Table des Mati√®res

1. [Vue d'Ensemble](#vue-densemble)
2. [Phase 1 : Infrastructure & Tests](#phase-1--infrastructure--tests)
3. [Phase 2 : Real LLM Integration](#phase-2--real-llm-integration)
4. [Phase 3 : Long-Term Memory](#phase-3--long-term-memory)
5. [Phase 4 : Polish & Production](#phase-4--polish--production)

---

## üéØ Vue d'Ensemble

### Priorit√©s (dans l'ordre)

```
1. Tests React Components    (2 jours)   - Fondation pour √©viter r√©gressions
2. Error Handling UI          (1 jour)    - Am√©liore UX avant LLM r√©el
3. Real LLM Integration       (3 jours)   - Feature principale Sprint 3
4. IndexedDB Migration        (1 jour)    - Scalabilit√© conversations
5. Long-Term Memory (RAG)     (2 jours)   - Feature avanc√©e
```

### Philosophie

- ‚úÖ **Tests d'abord** : Avant de toucher au LLM, on s√©curise ce qui existe
- ‚úÖ **Incr√©mental** : Petits commits, validation continue
- ‚úÖ **Rollback-friendly** : Chaque phase peut √™tre annul√©e sans casser le reste
- ‚úÖ **Documentation as code** : Chaque feature = ADR (Architecture Decision Record)

---

## üì¶ Phase 1 : Infrastructure & Tests (Jours 1-2)

### Objectif
S√©curiser la base de code existante avec des tests React avant de faire des changements majeurs.

### T√¢ches

#### 1.1 - Setup Testing Infrastructure

**Fichiers √† cr√©er :**
```bash
tests/setup/
‚îú‚îÄ‚îÄ react-test-utils.tsx       # Helpers de test (mock store, etc.)
‚îî‚îÄ‚îÄ vitest-setup.ts             # Configuration globale Vitest
```

**Actions :**
```bash
# Installer les d√©pendances
npm install -D @testing-library/react @testing-library/jest-dom @testing-library/user-event
```

**Fichier de config √† modifier :**
- `vitest.config.ts` : Ajouter `environment: 'happy-dom'`

**Validation :**
```bash
npm run test:unit -- --run
# Doit afficher "No test files found" mais pas d'erreur
```

---

#### 1.2 - Tests pour ModelLoadingView

**Fichier √† cr√©er :**
```
src/components/__tests__/ModelLoadingView.test.tsx
```

**Sc√©narios √† tester :**
1. ‚úÖ Phase "idle" ‚Üí Affiche "Initialisation..."
2. ‚úÖ Phase "downloading" ‚Üí Affiche barre de progression + stats
3. ‚úÖ Phase "compiling" ‚Üí Affiche "Compilation..."
4. ‚úÖ Phase "ready" ‚Üí Composant dispara√Æt (return null)
5. ‚úÖ Phase "error" ‚Üí Affiche message d'erreur
6. ‚úÖ Bouton pause/resume fonctionne
7. ‚úÖ Minimisation fonctionne

**Template de test :**
```typescript
import { describe, it, expect, vi } from 'vitest';
import { render, screen } from '@testing-library/react';
import { ModelLoadingView } from '../ModelLoadingView';
import { useKenshoStore } from '@/stores/useKenshoStore';

// Mock du store
vi.mock('@/stores/useKenshoStore');

describe('ModelLoadingView', () => {
  it('affiche la phase de t√©l√©chargement', () => {
    vi.mocked(useKenshoStore).mockReturnValue({
      modelProgress: { 
        phase: 'downloading', 
        progress: 0.5, 
        text: 'T√©l√©chargement...' 
      }
    });
    
    render(<ModelLoadingView />);
    expect(screen.getByText(/T√©l√©chargement/)).toBeInTheDocument();
  });
  
  // ... autres tests
});
```

**Validation :**
```bash
npm run test:unit -- ModelLoadingView
# Tous les tests passent ‚úÖ
```

---

#### 1.3 - Tests pour ChatInput

**Fichier √† cr√©er :**
```
src/components/__tests__/ChatInput.test.tsx
```

**Sc√©narios :**
1. ‚úÖ Input d√©sactiv√© si `modelReady = false`
2. ‚úÖ Input d√©sactiv√© si `isKenshoWriting = true`
3. ‚úÖ Soumission appelle `sendMessage()`
4. ‚úÖ Input se vide apr√®s soumission
5. ‚úÖ Suggestions affich√©es si `showSuggestions = true`
6. ‚úÖ Bouton attachement pr√©sent
7. ‚úÖ Bouton voix pr√©sent

**Validation :**
```bash
npm run test:unit -- ChatInput
```

---

#### 1.4 - Tests pour AIResponse

**Fichier √† cr√©er :**
```
src/components/__tests__/AIResponse.test.tsx
```

**Sc√©narios :**
1. ‚úÖ Affiche le contenu du message
2. ‚úÖ Affiche "thinking" si fourni
3. ‚úÖ Section thinking peut √™tre collapsed/expanded
4. ‚úÖ Boutons d'action pr√©sents (like, copy, regenerate)

**Validation :**
```bash
npm run test:unit -- AIResponse
```

---

#### 1.5 - Tests pour MessageBubble

**Fichier √† cr√©er :**
```
src/components/__tests__/MessageBubble.test.tsx
```

**Sc√©narios :**
1. ‚úÖ Affiche le texte du message
2. ‚úÖ Menu dropdown pr√©sent
3. ‚úÖ Options : Edit, Archive, Delete

---

#### 1.6 - Tests d'int√©gration Index.tsx

**Fichier √† cr√©er :**
```
src/pages/__tests__/Index.test.tsx
```

**Sc√©narios :**
1. ‚úÖ Appelle `init()` au montage
2. ‚úÖ Affiche ModelLoadingView si `!modelReady`
3. ‚úÖ Affiche chat si `modelReady`
4. ‚úÖ Auto-scroll fonctionne

---

### Livrable Phase 1

- ‚úÖ 20+ tests React qui passent
- ‚úÖ Coverage > 70% sur components/
- ‚úÖ CI passe sans erreur
- ‚úÖ Commit : `test: Add comprehensive React component tests`

---

## üé® Phase 2A : Error Handling UI (Jour 3)

### Objectif
Ajouter un syst√®me de notifications Toast pour les erreurs syst√®me.

### T√¢ches

#### 2A.1 - Ajouter Sonner Toast

**D√©j√† install√© :** `sonner` est dans `package.json` ‚úÖ

**Fichier √† cr√©er :**
```
src/hooks/useToast.ts
```

**Contenu :**
```typescript
import { toast } from 'sonner';

export const useToast = () => ({
  success: (message: string) => toast.success(message),
  error: (message: string) => toast.error(message),
  info: (message: string) => toast.info(message),
});
```

---

#### 2A.2 - Int√©grer dans useKenshoStore

**Fichier √† modifier :**
```
src/stores/useKenshoStore.ts
```

**Changements :**
```typescript
// Au lieu de mettre l'erreur dans le message Kensho
onError: (error) => {
  toast.error(`Erreur de communication: ${error.message}`);
  set({ isKenshoWriting: false });
}
```

---

#### 2A.3 - G√©rer les erreurs Workers

**Dans `startConstellation` :**
```typescript
llmWorker.onerror = (error) => {
  toast.error('‚ùå Le worker LLM a crash√©. Tentative de red√©marrage...');
  // Logique de retry
};
```

---

### Livrable Phase 2A

- ‚úÖ Toasts affich√©s pour erreurs syst√®me
- ‚úÖ Messages Kensho ne contiennent plus d'erreurs techniques
- ‚úÖ UX am√©lior√©e
- ‚úÖ Commit : `feat(ui): Add toast notifications for system errors`

---

## üß† Phase 2B : Real LLM Integration (Jours 4-6)

### Objectif
R√©soudre le build OOM et activer le vrai WebLLM.

### Strat√©gie : Dynamic Import

Au lieu de bundler `@mlc-ai/web-llm` dans le worker, on va le charger dynamiquement.

---

#### 2B.1 - Cr√©er un nouveau LLM Agent avec Dynamic Import

**Fichier √† cr√©er :**
```
src/agents/llm/dynamic.ts
```

**Contenu :**
```typescript
import { runAgent } from '../../core/agent-system/defineAgent';
import { AgentRuntime, AgentStreamEmitter } from '../../core/agent-system/AgentRuntime';

runAgent({
  name: 'MainLLMAgent',
  init: async (runtime: AgentRuntime) => {
    runtime.log('info', 'Chargement dynamique de WebLLM...');
    
    // Import dynamique (ne sera PAS bundl√©)
    const webllm = await import('@mlc-ai/web-llm');
    const engine = await webllm.CreateMLCEngine('Phi-3-mini-4k-instruct-q4f16_1-MLC');
    
    runtime.log('info', 'WebLLM charg√© avec succ√®s');
    
    // Progression du mod√®le
    engine.setInitProgressCallback((report) => {
      self.postMessage({
        type: 'MODEL_PROGRESS',
        payload: {
          phase: report.progress < 1 ? 'downloading' : 'compiling',
          progress: report.progress,
          text: report.text
        }
      });
    });
    
    self.postMessage({ type: 'READY' });
    
    runtime.registerStreamMethod('generateResponse', async (payload, stream) => {
      const [prompt] = payload.args;
      
      const messages = [{ role: 'user', content: prompt }];
      
      // Streaming avec WebLLM
      const completion = await engine.chat.completions.create({
        messages,
        stream: true,
      });
      
      for await (const chunk of completion) {
        const text = chunk.choices[0]?.delta?.content || '';
        if (text) stream.chunk({ text });
      }
      
      stream.end();
    });
  }
});
```

---

#### 2B.2 - Configuration Build Optimis√©e

**Fichier √† cr√©er :**
```
vite.llm-dynamic.config.ts
```

**Contenu :**
```typescript
import { defineConfig } from 'vite';

export default defineConfig({
  build: {
    lib: {
      entry: 'src/agents/llm/dynamic.ts',
      name: 'LLMAgent',
      fileName: 'llm.agent',
      formats: ['es']
    },
    rollupOptions: {
      external: ['@mlc-ai/web-llm'], // NE PAS bundler WebLLM
      output: {
        globals: {
          '@mlc-ai/web-llm': 'webllm'
        }
      }
    }
  }
});
```

---

#### 2B.3 - CDN Fallback pour WebLLM

**Option alternative si dynamic import √©choue :**

Charger WebLLM depuis un CDN dans le worker :

```typescript
// Dans dynamic.ts
importScripts('https://cdn.jsdelivr.net/npm/@mlc-ai/web-llm@latest/dist/index.js');
```

---

#### 2B.4 - Fallback vers Mock si √©chec

**Fichier √† modifier :**
```
src/stores/useKenshoStore.ts - fonction startConstellation
```

**Logique :**
```typescript
const startLLMWorker = () => {
  try {
    // Essayer d'abord le vrai LLM
    const llmWorker = new Worker('/dist/agents/llm.agent.js', { type: 'module' });
    
    llmWorker.onerror = () => {
      console.error('√âchec LLM r√©el, fallback vers Mock');
      toast.info('‚öôÔ∏è Utilisation du mode simulation (Mock LLM)');
      
      // Charger le Mock
      const mockWorker = new Worker('/dist/test-agents/llm.agent.js', { type: 'module' });
      // ... setup
    };
    
  } catch {
    // Fallback imm√©diat vers Mock
  }
};
```

---

#### 2B.5 - Tests avec Mod√®les L√©gers

**Mod√®les √† tester (par ordre de taille) :**

1. **TinyLlama-1.1B-Chat-v1.0-q4f16_1-MLC** (~700MB) - D√©j√† dans le code
2. **Phi-3-mini-4k-instruct-q4f16_1-MLC** (~2GB) - Recommand√©
3. **Qwen2.5-0.5B-Instruct-q4f16_1-MLC** (~350MB) - Le plus l√©ger

**Strat√©gie :**
- Commencer par Qwen 0.5B pour valider le flow
- Monter en gamme si √ßa passe

---

### Validation Phase 2B

**Checklist :**
```bash
# 1. Build sans OOM
npm run build:llm-dynamic
# ‚úÖ G√©n√®re dist/agents/llm.agent.js sans crasher

# 2. Test m√©moire
# Ouvrir Chrome DevTools > Memory
# Lancer l'app, v√©rifier que m√©moire < 500MB pendant chargement mod√®le

# 3. Test fonctionnel
# Envoyer un message, v√©rifier streaming fonctionne

# 4. Test fallback
# Simuler √©chec (renommer le fichier worker), v√©rifier que Mock prend le relais
```

---

### Livrable Phase 2B

- ‚úÖ LLM r√©el fonctionne en production
- ‚úÖ Build ne fait plus OOM
- ‚úÖ Fallback gracieux vers Mock si √©chec
- ‚úÖ Commit : `feat(llm): Dynamic import for WebLLM with graceful fallback`

---

## üíæ Phase 3 : IndexedDB Migration (Jour 7)

### Objectif
Migrer de `localStorage` (limit√© √† ~5MB) vers IndexedDB (~50MB-1GB).

---

### 3.1 - Cr√©er le Storage Adapter

**Fichier √† cr√©er :**
```
src/core/storage/ConversationStore.ts
```

**Contenu :**
```typescript
import { openDB, IDBPDatabase } from 'idb';
import { Message } from '@/stores/useKenshoStore';

const DB_NAME = 'kensho-db';
const STORE_NAME = 'conversations';
const DB_VERSION = 1;

class ConversationStore {
  private db: IDBPDatabase | null = null;

  async init() {
    this.db = await openDB(DB_NAME, DB_VERSION, {
      upgrade(db) {
        if (!db.objectStoreNames.contains(STORE_NAME)) {
          const store = db.createObjectStore(STORE_NAME, { keyPath: 'id', autoIncrement: true });
          store.createIndex('timestamp', 'timestamp');
        }
      },
    });
  }

  async saveMessages(messages: Message[]) {
    if (!this.db) await this.init();
    const tx = this.db!.transaction(STORE_NAME, 'readwrite');
    
    // Sauvegarder chaque message
    for (const msg of messages) {
      await tx.store.put(msg);
    }
    
    await tx.done;
  }

  async loadMessages(): Promise<Message[]> {
    if (!this.db) await this.init();
    return this.db!.getAll(STORE_NAME);
  }

  async clearAll() {
    if (!this.db) await this.init();
    await this.db!.clear(STORE_NAME);
  }
}

export const conversationStore = new ConversationStore();
```

**D√©pendance √† installer :**
```bash
npm install idb
```

---

### 3.2 - Modifier useKenshoStore

**Fichier √† modifier :**
```
src/stores/useKenshoStore.ts
```

**Changements :**
```typescript
import { conversationStore } from '../core/storage/ConversationStore';

// Remplacer loadMessagesFromLocalStorage
const loadMessagesFromStorage = async (): Promise<Message[]> => {
  try {
    return await conversationStore.loadMessages();
  } catch (error) {
    console.error('[KenshoStore] Erreur IndexedDB, fallback localStorage');
    // Fallback vers localStorage
    const stored = localStorage.getItem('kensho_conversation_history');
    return stored ? JSON.parse(stored) : [];
  }
};

// Remplacer saveMessagesToLocalStorage
const saveMessagesToStorage = async (messages: Message[]) => {
  try {
    await conversationStore.saveMessages(messages);
  } catch (error) {
    console.error('[KenshoStore] Erreur IndexedDB');
  }
};
```

---

### 3.3 - Migration des Donn√©es Existantes

**Fichier √† cr√©er :**
```
src/utils/migrateToIndexedDB.ts
```

**Script de migration :**
```typescript
export async function migrateLocalStorageToIndexedDB() {
  const oldData = localStorage.getItem('kensho_conversation_history');
  if (!oldData) return;
  
  const messages = JSON.parse(oldData);
  await conversationStore.saveMessages(messages);
  
  // Garder localStorage comme backup pendant 1 version
  console.log('‚úÖ Migration vers IndexedDB termin√©e');
}
```

**Appeler dans `useKenshoStore.init()` :**
```typescript
init: async () => {
  await migrateLocalStorageToIndexedDB();
  // ... reste
}
```

---

### Validation Phase 3

```bash
# 1. Ouvrir DevTools > Application > IndexedDB
# V√©rifier que "kensho-db" existe avec les messages

# 2. Envoyer 500 messages (script de test)
# V√©rifier que tout fonctionne (localStorage aurait crash√©)
```

---

### Livrable Phase 3

- ‚úÖ Conversations stock√©es dans IndexedDB
- ‚úÖ Capacit√© : 50MB+ (vs 5MB localStorage)
- ‚úÖ Migration automatique depuis localStorage
- ‚úÖ Commit : `feat(storage): Migrate to IndexedDB for scalable conversation storage`

---

## üß† Phase 4 : Long-Term Memory (RAG Lite) (Jours 8-9)

### Objectif
Donner √† Kensho une m√©moire contextuelle via RAG simple.

---

### 4.1 - Embeddings avec Transformers.js

**Installer :**
```bash
npm install @xenova/transformers
```

**Fichier √† cr√©er :**
```
src/core/memory/EmbeddingEngine.ts
```

**Contenu :**
```typescript
import { pipeline } from '@xenova/transformers';

class EmbeddingEngine {
  private embedder: any = null;

  async init() {
    this.embedder = await pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2');
  }

  async embed(text: string): Promise<number[]> {
    const output = await this.embedder(text, { pooling: 'mean', normalize: true });
    return Array.from(output.data);
  }
}

export const embeddingEngine = new EmbeddingEngine();
```

---

### 4.2 - Vector Store Simple

**Fichier √† cr√©er :**
```
src/core/memory/VectorStore.ts
```

**Contenu :**
```typescript
interface MemoryEntry {
  id: string;
  text: string;
  embedding: number[];
  timestamp: number;
}

class VectorStore {
  private memories: MemoryEntry[] = [];

  async add(text: string) {
    const embedding = await embeddingEngine.embed(text);
    this.memories.push({
      id: `mem-${Date.now()}`,
      text,
      embedding,
      timestamp: Date.now()
    });
  }

  async search(query: string, topK = 3): Promise<string[]> {
    const queryEmbedding = await embeddingEngine.embed(query);
    
    // Cosine similarity
    const similarities = this.memories.map(mem => ({
      text: mem.text,
      score: this.cosineSimilarity(queryEmbedding, mem.embedding)
    }));
    
    return similarities
      .sort((a, b) => b.score - a.score)
      .slice(0, topK)
      .map(s => s.text);
  }

  private cosineSimilarity(a: number[], b: number[]): number {
    const dot = a.reduce((sum, val, i) => sum + val * b[i], 0);
    const magA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
    const magB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
    return dot / (magA * magB);
  }
}

export const vectorStore = new VectorStore();
```

---

### 4.3 - Int√©grer RAG dans le Flux

**Fichier √† modifier :**
```
src/stores/useKenshoStore.ts - sendMessage()
```

**Changement :**
```typescript
sendMessage: async (text) => {
  // 1. Rechercher dans la m√©moire
  const relevantMemories = await vectorStore.search(text);
  
  // 2. Construire le contexte
  const context = relevantMemories.length > 0 
    ? `Contexte pertinent:\n${relevantMemories.join('\n')}\n\n`
    : '';
  
  // 3. Envoyer avec contexte
  const enrichedQuery = context + text;
  
  // 4. Apr√®s r√©ponse, stocker dans m√©moire
  vectorStore.add(`User: ${text}\nKensho: ${responseText}`);
}
```

---

### Validation Phase 4

**Test manuel :**
```
1. "Je m'appelle Alice"
2. (20 messages plus tard) "Comment je m'appelle ?"
3. Kensho doit r√©pondre "Alice"
```

---

### Livrable Phase 4

- ‚úÖ RAG fonctionnel avec embeddings
- ‚úÖ Top-3 retrieval
- ‚úÖ M√©moire persistante
- ‚úÖ Commit : `feat(memory): Add RAG-based long-term memory with embeddings`

---

## üé® Phase 5 : Polish & Production (Jour 10)

### 5.1 - Refactor & Code Review

- ‚úÖ Revoir tous les TODOs
- ‚úÖ Nettoyer les console.log
- ‚úÖ V√©rifier les types TypeScript
- ‚úÖ Formater avec Prettier

---

### 5.2 - Documentation

**Fichiers √† mettre √† jour :**
- `README.md` : Ajouter section RAG + Real LLM
- `SPRINT3_COMPLETION.md` : Rapport final
- `docs/GETTING_STARTED.md` : Instructions mise √† jour

---

### 5.3 - Performance Check

**Benchmarks √† lancer :**
```bash
npm run benchmark:throughput
npm run benchmark:latency
```

---

### 5.4 - Final Commit & Release

```bash
git add .
git commit -m "feat: Complete Sprint 3 - Real LLM, Tests, RAG, IndexedDB"
git tag v0.3.0
git push origin sprint-3 --tags
```

---

## üìä R√©sum√© du Plan

| Phase | Dur√©e | Priorit√© | Risque |
|-------|-------|----------|--------|
| 1. Tests React | 2j | üî¥ Haute | Faible |
| 2A. Error UI | 1j | üü° Moyenne | Faible |
| 2B. Real LLM | 3j | üî¥ Haute | **√âlev√©** (OOM) |
| 3. IndexedDB | 1j | üü¢ Basse | Faible |
| 4. RAG | 2j | üü° Moyenne | Moyen |
| 5. Polish | 1j | üü¢ Basse | Faible |

**Total : ~10 jours**

---

## üö® Points de Vigilance

### Build OOM (Phase 2B)

**Si le dynamic import ne r√©sout pas le OOM :**

**Plan B :** Utiliser un CDN externe
```typescript
// Charger WebLLM depuis esm.sh ou jsDelivr
import('https://esm.sh/@mlc-ai/web-llm@0.2.79')
```

**Plan C :** Utiliser une API backend
```typescript
// D√©porter l'inf√©rence vers un serveur Node.js/Python
fetch('/api/generate', { method: 'POST', body: prompt })
```

**Plan D :** Garder le Mock pour Sprint 3, refaire tentative en Sprint 4 avec plus de RAM

---

### Tests Flaky

**Si les tests React sont instables :**
- Utiliser `waitFor` de Testing Library
- Mocker tous les timers avec `vi.useFakeTimers()`
- Nettoyer apr√®s chaque test : `afterEach(() => { cleanup(); })`

---

### RAG Performance

**Si les embeddings sont trop lents :**
- Utiliser un mod√®le plus l√©ger (DistilBERT au lieu de MiniLM)
- Cache les embeddings d√©j√† calcul√©s
- Limiter √† 100 derniers messages

---

## ‚úÖ Checklist Finale

Avant de consid√©rer Sprint 3 termin√© :

- [ ] Tous les tests passent (`npm run test`)
- [ ] Type-check OK (`npm run type-check`)
- [ ] Lint OK (`npm run lint`)
- [ ] Build production OK (`npm run build`)
- [ ] D√©mo fonctionnelle (enregistrer vid√©o)
- [ ] Documentation √† jour
- [ ] `SPRINT3_COMPLETION.md` r√©dig√©
- [ ] Tag Git `v0.3.0` cr√©√©
- [ ] PR merg√©e dans `main`

---

**Bonne chance ! üöÄ**
