# Kensho - FactCheckerAgent & Learning System

## Overview
Kensho is an advanced AI debate orchestration system featuring meta-critique validation, cognitive traceability, performance monitoring, and feedback-driven learning. It is now enhanced with robust fact-checking capabilities and a **production-ready asynchronous kernel** (Sprint 12). The project aims to provide transparent, verifiable, and nuanced AI-generated insights. Kensho is designed to reduce AI hallucinations, improve response reliability, and offer a transparent view into the AI's reasoning process.

## User Preferences
I prefer detailed explanations and transparency in the AI's operations. I want to see the cognitive process and verification steps clearly. I value robust error handling and graceful degradation in system responses. I prefer a modular and extensible architecture. I would like the agent to prioritize reliability and factual accuracy. I prefer that the agent asks before making major changes to the system architecture.

## System Architecture
Kensho's architecture is built around a multi-agent debate system that includes Optimist, Critic, and MetaCritic agents, orchestrated in a 4-step flow with graceful degradation. Cognitive traceability is provided via a `JournalCognitif` system, logging all debate steps and decisions.

### Sprint 12: Le C≈ìur Asynchrone (Kernel v2.0)
**Date:** Novembre 2025  
**Statut:** ‚úÖ Impl√©ment√© et Production-Ready

Le Sprint 12 introduit un noyau asynchrone robuste pour g√©rer les mod√®les IA et les ressources syst√®me de mani√®re optimale:

**Composants principaux:**
- **ModelManager v2.0** (`src/core/kernel/ModelManager.ts`): Gestionnaire asynchrone de mod√®les WebLLM avec:
  - Initialisation explicite et promesse `ready` pour √©viter les race conditions
  - Support du changement de mod√®le √† chaud via `switchModel()`
  - Tracking de l'√©tat actuel du mod√®le charg√©
  - Gestion du cycle de vie complet (init ‚Üí dispose)
  - Callback de progression pour l'UI
  
- **ResourceManager v1.0** (`src/core/kernel/ResourceManager.ts`): Syst√®me nerveux sensoriel surveillant:
  - **M√©moire**: Utilisation JS heap, tendances (rising/falling/stable), d√©tection >85%
  - **Batterie**: Niveau, √©tat de charge, temps avant d√©charge
  - **R√©seau**: √âtat online/offline, type de connexion (4G/3G/2G), latence RTT
  - **CPU**: Nombre de c≈ìurs logiques, d√©tection de throttling
  - **Mode √©co**: D√©tection automatique du mode √©conomie d'√©nergie
  - Syst√®me d'√©v√©nements r√©actifs (`on('memory-critical')`, `on('battery-low')`, etc.)
  - Cache temporel (500ms) pour √©viter les lectures excessives
  
- **KernelCoordinator** (`src/core/kernel/KernelCoordinator.ts`): Orchestrateur intelligent qui:
  - Coordonne ModelManager et ResourceManager
  - Prend des d√©cisions de chargement bas√©es sur les ressources (`canLoadModel()`)
  - G√®re les √©v√©nements critiques (m√©moire satur√©e ‚Üí notification)
  - Fournit une API unifi√©e pour l'application
  
- **ModelCatalog** (`src/core/kernel/ModelCatalog.ts`): Catalogue centralis√© des mod√®les:
  - `gemma-3-270m-it-MLC`: Noyau de dialogue ultra-compact (270M, q4f16_1)
  - Consommation optimale: 0.75% batterie pour 25 conversations
  - Extensible pour futurs mod√®les (embeddings, sp√©cialis√©s)

**Corrections de bugs critiques:**
- Fix `hasMemoryAPI`: Utilise `performance.memory` au lieu de `navigator.deviceMemory`
- Gestion compl√®te des event listeners avec cleanup pour √©viter memory leaks
- Validation robuste des propri√©t√©s optionnelles (`connection.effectiveType`)

**Architecture:**
```
Application
    ‚Üì
KernelCoordinator (Orchestration)
    ‚Üì                    ‚Üì
ModelManager     ResourceManager
(Que charger)    (Quand charger)
    ‚Üì                    ‚Üì
WebLLM Engine    Browser APIs
```

**Usage:**
```typescript
import { kernelCoordinator } from '@/core/kernel';

// Initialisation
await kernelCoordinator.init('gemma-3-270m', (progress) => {
  console.log(progress.text);
});

// Changement de mod√®le intelligent
await kernelCoordinator.switchModel('qwen2-e5-embed');

// V√©rification des ressources
const decision = await kernelCoordinator.canLoadModel('heavy-model');
if (!decision.canLoad) {
  console.warn(decision.reason); // "M√©moire satur√©e", "Batterie critique", etc.
}
```

The FactCheckerAgent employs a hybrid approach for claim extraction (LLM + Rule-Based fallback) and a 2-step verification process (semantic search via HNSW embeddings + LLM Judge). Verification results include status (VERIFIED, CONTRADICTED, AMBIGUOUS, UNKNOWN), confidence scores, and evidence tracking.

**UI/UX Decisions:**
- **JournalCognitifView:** A timeline-based UI for cognitive traceability, displaying debate steps and detailed fact-checking results.
- **VerificationResultItem:** Visualizes fact-check status with color-coded icons (‚úÖ, ‚ùå, üü°, ‚ö†Ô∏è), claim text, confidence scores, and evidence previews.
- **ChatMessage:** Features a `SourcesFooter` to display consulted sources with badges and tooltips, enhancing transparency.
- **ObservatoryModal:** A 4-tabbed interface for monitoring and feedback.

**Technical Implementations & Design Choices:**
- **Hybrid Claim Extraction:** Combines LLM flexibility for complex context with rule-based determinism for guaranteed output and fallback. Multi-level parsing (JSON ‚Üí Markdown ‚Üí Rules) ensures robustness.
- **Semantic Verification:** Utilizes `EmbeddingAgent` and `GraphWorker.findEvidence` for efficient semantic search against a knowledge graph, judged by a minimalist LLM prompt for fast verdicts.
- **Graceful Degradation:** The system can return a draft response directly if meta-critique validation scores are below a dynamic threshold, preventing low-quality AI outputs.
- **Performance Optimization:** Parallelized Optimist and Critic agent execution to reduce latency.
- **Feedback Learning:** `FeedbackLearner` dynamically adjusts thresholds based on user feedback to improve MetaCritic accuracy.
- **Enhanced Type System:** Robust type definitions and validation (`MessageMetadata`, `isValidWorkerName`).
- **Centralized Utilities:** UUID generation and configurable logging strategies (`ConsoleLogger`, `BufferedLogger`, `NoOpLogger`).
- **JSONExtractor Enhancements:** Supports various Markdown JSON formats, single-quote conversion, and strict/lenient parsing modes.
- **CalculatorAgent Security:** Limited `mathjs` scopes to reduce attack surface and bundle size.

## External Dependencies
- **LLM Providers:** Used for agent reasoning, claim extraction, and verification. Specific models are abstracted but critical to agent operations.
- **HNSW (Hierarchical Navigable Small Worlds):** Used by `GraphWorker.findEvidence` for efficient semantic search and embedding storage.
- **`mathjs`:** Utilized by `CalculatorAgent` for mathematical operations (with limited scopes for security).
- **External Knowledge Graph/Database:** Implied for semantic search and evidence retrieval during fact-checking.