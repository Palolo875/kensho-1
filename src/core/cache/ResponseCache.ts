// src/core/cache/ResponseCache.ts

import { LRUCache } from 'lru-cache';
import { v5 as uuidv5 } from 'uuid';

console.log("üíæ‚ú® Initialisation du ResponseCache v1.0 (Elite)...");

// Namespace unique pour notre hashing, pour √©viter les collisions
const CACHE_NAMESPACE = 'f5b4b7a0-9b3c-4b1e-8b0a-0e1e2e3e4f5a';

type CachedResponse = {
  response: string;
  modelUsed: string;
  timestamp: number;
  tokens?: number; // Nombre de tokens g√©n√©r√©s
};

/**
 * Cache intelligent des r√©ponses LLM avec une politique d'√©viction LRU.
 */
class ResponseCache {
  private cache: LRUCache<string, CachedResponse>;
  private hits = 0;
  private misses = 0;

  constructor() {
    this.cache = new LRUCache<string, CachedResponse>({
      max: 100, // Garde les 100 r√©ponses les plus r√©centes
      ttl: 1000 * 60 * 30, // TTL de 30 minutes par d√©faut
      updateAgeOnGet: true, // Remet le TTL √† z√©ro √† chaque acc√®s
    });
  }

  /**
   * Cr√©e une cl√© de cache unique et d√©terministe pour un prompt et un mod√®le.
   */
  private getCacheKey(prompt: string, modelKey: string): string {
    const data = `${modelKey.trim()}:${prompt.trim()}`;
    return uuidv5(data, CACHE_NAMESPACE);
  }

  /**
   * R√©cup√®re une r√©ponse depuis le cache.
   * @returns La r√©ponse cach√©e ou `null` si non trouv√©e.
   */
  public get(prompt: string, modelKey: string): CachedResponse | null {
    const key = this.getCacheKey(prompt, modelKey);
    const cached = this.cache.get(key);

    if (cached) {
      this.hits++;
      console.log(`[Cache] ‚úÖ HIT! (Taux de succ√®s: ${((this.hits / (this.hits + this.misses)) * 100).toFixed(1)}%)`);
      return cached;
    }

    this.misses++;
    console.log(`[Cache] ‚ùå MISS.`);
    return null;
  }

  /**
   * Ajoute une nouvelle r√©ponse au cache.
   * @param prompt - Prompt utilisateur
   * @param modelKey - Mod√®le utilis√©
   * @param response - R√©ponse g√©n√©r√©e
   * @param tokens - Nombre de tokens g√©n√©r√©s (optionnel)
   */
  public set(prompt: string, modelKey: string, response: string, tokens?: number): void {
    const key = this.getCacheKey(prompt, modelKey);
    this.cache.set(key, {
      response,
      modelUsed: modelKey,
      timestamp: Date.now(),
      tokens,
    });
    console.log(`[Cache] üíæ R√©ponse pour ${modelKey} sauvegard√©e.`);
  }

  /**
   * Vide compl√®tement le cache.
   */
  public clear(): void {
    this.cache.clear();
    this.hits = 0;
    this.misses = 0;
    console.log("[Cache] Cache vid√©.");
  }

  /**
   * Obtient les statistiques du cache
   */
  public getStats() {
    const total = this.hits + this.misses;
    return {
      hits: this.hits,
      misses: this.misses,
      hitRate: total > 0 ? ((this.hits / total) * 100).toFixed(1) : '0.0',
      size: this.cache.size,
    };
  }
}

export const responseCache = new ResponseCache();
