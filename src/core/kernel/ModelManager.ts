import { MLCEngine, CreateMLCEngine, InitProgressReport } from "@mlc-ai/web-llm";
import { MODEL_CATALOG, ModelMeta } from "./ModelCatalog";
import { memoryManager } from "./MemoryManager";
import { sseStreamer } from "../streaming/SSEStreamer";
import { WEBLLM_CONFIG } from "../../config/webllm.config";

console.log("üì¶ Initialisation du ModelManager v3.1 (Memory-Aware + Streaming)...");

export class ModelManager {
  private engine: MLCEngine | null = null;
  private _ready!: Promise<void>;
  private _resolveReady!: () => void;
  private _rejectReady!: (error: any) => void;
  private currentModelKey: string | null = null;
  private isInitialized = false;
  private isInitializing = false;

  constructor() {
    this.resetReadyPromise();
  }

  public get ready(): Promise<void> {
    return this._ready;
  }

  private resetReadyPromise() {
    this._ready = new Promise<void>((resolve, reject) => {
      this._resolveReady = resolve;
      this._rejectReady = reject;
    });
  }

  public async init(
    defaultModelKey = "gemma-2-2b", 
    progressCallback?: (report: InitProgressReport) => void
  ) {
    if (this.isInitialized) {
      console.warn("[ModelManager] Init d√©j√† appel√©, ignor√©.");
      return;
    }

    if (this.isInitializing) {
      console.warn("[ModelManager] Init en cours, attente...");
      await this.ready;
      return;
    }

    this.isInitializing = true;

    try {
      console.log("[ModelManager] Initialisation du moteur WebLLM...");
      
      const modelMeta = MODEL_CATALOG[defaultModelKey];
      if (!modelMeta) {
        throw new Error(`Mod√®le inconnu dans le catalogue : ${defaultModelKey}`);
      }

      console.log(`[ModelManager] Pr√©-chargement du mod√®le par d√©faut : ${modelMeta.model_id}`);
      
      const config: any = {};
      if (progressCallback) {
        config.initProgressCallback = progressCallback;
      }
      
      // Use default WebLLM models (custom appConfig not needed for official models)
      this.engine = await CreateMLCEngine(modelMeta.model_id, config);
      
      // TODO Sprint 16: Tracker tailles r√©elles via CacheManager WebLLM ou fetch hooks
      // InitProgressReport.total n'est PAS la taille en bytes (juste un compteur de progression)
      
      this.currentModelKey = defaultModelKey;
      this.isInitialized = true;
      this.isInitializing = false;
      
      // ‚ú® Enregistrer le mod√®le charg√© dans MemoryManager
      memoryManager.registerLoaded(defaultModelKey);
      
      // ‚ú® Notifier l'UI via SSE
      sseStreamer.streamInfo(`Model ${defaultModelKey} initialized and ready.`);
      
      this._resolveReady();
      console.log("‚úÖ [ModelManager] Pr√™t. Le noyau de dialogue est op√©rationnel.");

    } catch (error) {
      console.error("[ModelManager] √âchec critique de l'initialisation.", error);
      this.isInitializing = false;
      this._rejectReady(error);
      this.resetReadyPromise();
      throw error;
    }
  }

  public async getEngine(): Promise<MLCEngine> {
    await this.ready;
    if (!this.engine) {
      throw new Error("Le moteur n'a pas pu √™tre initialis√©.");
    }
    return this.engine;
  }

  public async switchModel(modelKey: string, progressCallback?: (report: InitProgressReport) => void) {
    await this.ready;
    
    if (this.currentModelKey === modelKey) {
      console.log(`[ModelManager] Mod√®le ${modelKey} d√©j√† charg√©.`);
      // ‚ú® Marquer comme r√©cemment utilis√© (LRU)
      memoryManager.touch(modelKey);
      return;
    }

    const modelMeta = MODEL_CATALOG[modelKey];
    if (!modelMeta) {
      throw new Error(`Mod√®le inconnu : ${modelKey}`);
    }
    
    // ‚ú® Notifier l'UI du changement
    sseStreamer.streamInfo(`Checking memory for ${modelKey}...`);
    
    // ‚ú® V√©rifier si assez de VRAM pour charger le nouveau mod√®le
    const canLoad = await memoryManager.canLoadModel(modelKey);
    if (!canLoad.can) {
      console.warn(`[ModelManager] ‚ö†Ô∏è ${canLoad.reason}`);
      // ‚ú® Notifier l'UI de l'erreur
      sseStreamer.streamError(new Error(`Cannot load ${modelKey}: ${canLoad.reason}`));
      throw new Error(`Impossible de charger ${modelKey}: ${canLoad.reason}`);
    }
    
    console.log(`[ModelManager] Changement vers ${modelMeta.model_id}`);
    sseStreamer.streamInfo(`Loading model ${modelKey}...`);
    
    const config: any = {};
    if (progressCallback) {
      config.initProgressCallback = progressCallback;
    }
    
    // ‚ú® D√©senregistrer l'ancien mod√®le si pr√©sent
    if (this.currentModelKey) {
      memoryManager.registerUnloaded(this.currentModelKey);
    }
    
    // Use default WebLLM models (custom appConfig not needed for official models)
    await this.engine!.reload(modelMeta.model_id, config);
    
    // TODO Sprint 16: Tracker tailles r√©elles via CacheManager WebLLM ou fetch hooks
    // InitProgressReport.total n'est PAS la taille en bytes
    
    this.currentModelKey = modelKey;
    
    // ‚ú® Enregistrer le nouveau mod√®le charg√©
    memoryManager.registerLoaded(modelKey);
    
    // ‚ú® Notifier l'UI du succ√®s
    sseStreamer.streamInfo(`Model ${modelKey} loaded successfully.`);
    console.log(`‚úÖ [ModelManager] Mod√®le ${modelKey} charg√© avec succ√®s.`);
  }

  public async preloadModel(modelKey: string): Promise<void> {
    await this.ready;
    
    const modelMeta = MODEL_CATALOG[modelKey];
    if (!modelMeta) {
      throw new Error(`Mod√®le inconnu : ${modelKey}`);
    }
    
    console.log(`[ModelManager] Pr√©-chargement en arri√®re-plan : ${modelMeta.model_id}`);
    await this.engine!.reload(modelMeta.model_id);
  }

  public getCurrentModel(): string | null {
    return this.currentModelKey;
  }

  public isModelLoaded(modelKey: string): boolean {
    return this.currentModelKey === modelKey;
  }

  public getAvailableModels(): Record<string, ModelMeta> {
    return MODEL_CATALOG;
  }

  public async dispose() {
    if (this.engine) {
      console.log("[ModelManager] Lib√©ration des ressources...");
      
      // ‚ú® D√©senregistrer le mod√®le actuel
      if (this.currentModelKey) {
        memoryManager.registerUnloaded(this.currentModelKey);
      }
      
      await this.engine.unload();
      this.engine = null;
      this.currentModelKey = null;
      this.isInitialized = false;
    }
  }

  /**
   * ‚ú® Retourne les stats VRAM du MemoryManager
   */
  public getVRAMStats() {
    return memoryManager.getStats();
  }
}

export const modelManager = new ModelManager();
